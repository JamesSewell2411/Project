{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project Code.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMMZdj6UhgcPelMCIX5uScs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SM9fu-NLjWeq","colab_type":"code","outputId":"7dd42f45-f9e1-460f-eaa3-1df434b8d2cd","executionInfo":{"status":"ok","timestamp":1587392869564,"user_tz":-60,"elapsed":21238,"user":{"displayName":"James Sewell","photoUrl":"","userId":"01314987295168297053"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vz5nXh68iief","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"3abd838f-0493-447e-996e-ada2b78b1f3a"},"source":["import random\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Activation, Conv1D, Add, MaxPooling1D, BatchNormalization\n","from tensorflow.keras.utils import to_categorical\n","\n","def PreProcess(FileName):\n","    #Function to preprocess data, will split proteins into individual list elements\n","    #and eliminate any much too long or much too short sequences\n","    #Requiers a filename of type TXT in the format \"Name.txt\"\n","    #Outputs the meta list, the sequence list and a count of proteins in them\n","\n","    FilePath = 'drive/My Drive/Project/'+FileName\n","    file = open(FilePath,\"r\")\n","    #Sets an active file from which to read\n","    #And sets it to read mode (rather than write mode)\n","    RawFile = file.readlines()\n","    #Reads each line to a new list element\n","    Sequence = []\n","    Meta = []\n","    #initialise empty lists to contain the sequence of amino acids and the \n","    #metadata of each sequence (Actual function etc)\n","    Count = -1\n","    #Initialises index (count) for the lists, to be able to access specific elements and\n","    #check the whole dataset is accessed.\n","    for row in RawFile:\n","        #For each row in the non binding amino acid sequence dataset\n","        if row[0] == \">\":\n","            #if the row starts with a >, it contains the metadata and a string of text\n","            #so this row is stored seperatly and marks the beginning of a new protei\n","            Count+=1\n","            #increment count\n","            Sequence.append(\"\")\n","            #add an element to the list for the new protein\n","            Meta.append(row)\n","            #and append the meta with the metadata\n","        else:\n","            row = row.replace(\"\\n\", \"\")#Remove all newline characters from the text string\n","            Sequence[Count] = Sequence[Count] + row\n","            #else, the row is sequence data and should be appended to the current running sequence\n","    \n","    length = []#Create a list to contain the length of the sequence list\n","    FinalMeta = []#The final sanitised output for MetaData (Unused but futureproof)\n","    FinalSequence = []#List to contain the final sequences after any too long or short are removed\n","    FinalLength = []#List containing the lengths of all finalSequence sequences (Essentially a parallel array, \n","    #would work in a 2D list but would need to be divided ever time its used\n","    \n","    MaxLength = 1000 #The max sequence length. Anything larger would be anomalous\n","    MinLength = 50 # Same for the min length\n","    Count = -1 #An index count\n","    for each in Sequence: # For ever item in sequence, add the length of that item to the lengths list\n","        length.append(len(each))\n","    for each in length:#for every item in length, if the associated sequence item is valid, add it to finalSequence\n","    #And finalMeta etc. otherwisse just move on\n","        Count+=1\n","        if each<=MaxLength and each>=MinLength:\n","            FinalMeta.append(Meta[Count])\n","            FinalSequence.append(Sequence[Count])\n","            FinalLength.append(length[Count])\n","    #Return FinalMeta, data on each sequence in case it's useful later, final sequence and finallength        \n","    return FinalMeta,FinalSequence,FinalLength\n","\n","def ConvertToInt(AASequences):\n","    #Must be parsed a list of Raw Amino Acid sequences, and replaces the letter codes with numbers\n","    #Then returns the changed list\n","    letterCodes = {'A':1, 'R':2, 'N':3, 'D':4, 'C':5, 'Q':6, 'E':7, 'G':8, 'H':9, 'I':10,\n","     'L':11, 'K':12, 'M':13, 'F':14, 'P':15, 'S':16, 'T':17, 'W':18, 'Y':19, 'V':20, 'U':21,\n","     'O':22}\n","    #Dictionary of Letter codes to convert, each represents a numeric value\n","    #Alanine = A, Arginine = R etc.\n","    #The addition of the 21st,\n","    #Selenocysteine = U came later\n","    #Pyrrolysine = O is 22\n","    #Other non essential amino acids are not included such as Aspartic Acid andGlutamic Acid\n","    #If they come up add them to the dictionary. otherwise they are too rare to conside\n","    #Especially with exclusivly human Amino Acids/Proteins\n","    intAll = []#List of lists for the integer converted sequences\n","    intProtein = []#list for each protein represented as integers\n","    for Sequence in AASequences:\n","      #for each sequence\n","        for each in Sequence:\n","          #for each letter\n","            intProtein.append(letterCodes[each])\n","            #lookup in dictionary the conversion, and add the conversion to the proteinList\n","        intAll.append(intProtein)\n","        #add the entier protein to the All list\n","        intProtein = []\n","    return intAll # return the list of lists of amino acid conversions\n","\n","def Pad(Binding, NonBinding, PadToLength):\n","    #Pads Each amino Acid sequence to a regular length to be parsed into the CNN properly\n","    #PAds to the largest length, in this case 1000\n","    for i in range(len(Binding)):\n","        #For each sequence\n","        while len(Binding[i])< PadToLength:\n","        #While its too short\n","            Binding[i].append(0)\n","            #Add the value \"0\" to the end\n","    for i in range(len(NonBinding)):\n","        while len(NonBinding[i]) < PadToLength:\n","            NonBinding[i].append(0)\n","    print(\"Padding Completed\")#Update terminal\n","    return Binding, NonBinding#Output Padded lists\n","\n","def Split(Binding, NonBinding):\n","    #Converts the binding and non binding into X and Y train, Val, and test sets.\n","    #and returns all 6 of thse sets XTrain, YTrain, XVal, YVal etc\n","    BindingArray = np.array(Binding) #Convert List to Array\n","    BindingLabelsArray = np.ones(len(Binding))#Create an array of ones for the Y data (1 is the boolean for Bunding=True)\n","    #and length equal to the amount of labels needed\n","    BindingArray.astype(int)#Converts the Array to an array of integers rather than floats or strings\n","    \n","    NonBindingArray = np.array(NonBinding)#Convert list to array\n","    NonBindingLabelsArray = np.zeros(len(NonBinding))#Create an array of Zeroes for the boolean for non binding for Y Data\n","    NonBindingArray.astype(int)#Converts the arrat to integer\n","    \n","    WholeDataset = np.concatenate((BindingArray,NonBindingArray), axis=0)#Concatenate both arrays to be shuffled (XData)\n","    WholeLabels = np.concatenate((BindingLabelsArray,NonBindingLabelsArray), axis=0)#concatenate labelarrays (YData)\n","    \n","    index = np.arange(len(WholeLabels))#Creates an index to shuffle both arryas the same way, to keep X and Y associated\n","    #The Index array is created with the values 1,2,3,4,5,6,7,8... to the length needed.\n","    np.random.shuffle(index)#Shuffles the index array randomly\n","    \n","    WholeDataset = WholeDataset[index]#Shuffles the XData to matsh the shuffled array\n","    WholeLabels = WholeLabels[index]#Shuffles the YData to match the shuffled array\n","    \n","    TrainDivision = round(len(WholeLabels) * 0.6)#Creates indexes where the data should be divided into Train\n","    ValidateDivision = round(len(WholeLabels) * 0.9)#Creates a second divide for Validation and test\n","    #80% Train, 10% Validate, 10% Test \n","    \n","    #Actual division of the data using array indexing 0 to divide, divide to divide, divide to end.\n","    Train = WholeDataset[:TrainDivision]#XTrain\n","    TrainLabels = WholeLabels[:TrainDivision]#YTrain\n","    Validate = WholeDataset[TrainDivision:ValidateDivision]#XValidate\n","    ValidateLabels = WholeLabels[TrainDivision:ValidateDivision]#YValidate\n","    Test = WholeDataset[ValidateDivision:]#XTest\n","    TestLabels = WholeLabels[ValidateDivision:]#YTest\n","    \n","    return (Train,TrainLabels,Validate,ValidateLabels,Test,TestLabels)#Returns the 6 arrays of data\n","\n","def EvaluateModel(Predictions):\n","    TruePositive = 0\n","    TrueNegative = 0\n","    FalsePositive = 0\n","    FalseNegative = 0\n","\n","    for i in range(len(Predictions)):\n","      #print(\"Predicted: \", round(Predictions[i][0]), \" Actual: \", TestY[i])\n","      if (TestY[i][0] == 1 and round(Predictions[i][0])) == 1:\n","        #True positive\n","        TruePositive+=1\n","      if TestY[i][0] == 0 and round(Predictions[i][0]) == 0:\n","        #True Negative\n","        #Predicted\n","        TrueNegative+=1\n","      if TestY[i][0] == 0 and round(Predictions[i][0]) == 1:\n","        #False Positive\n","        FalsePositive+=1\n","      if TestY[i][0] == 1 and round(Predictions[i][0]) == 0:\n","        #False Negative\n","        FalseNegative+=1\n","      \n","\n","    print(\"True Positive = \", TruePositive)\n","    print(\"True Negative = \", TrueNegative)\n","    print(\"False Positive = \", FalsePositive)\n","    print(\"False Negative = \", FalseNegative)\n","\n","    Accuracy = (TruePositive + TrueNegative) / (TruePositive + TrueNegative + FalsePositive + FalseNegative)\n","    Specificity = TrueNegative / (TrueNegative+FalsePositive)\n","    Precision = TruePositive / (TruePositive+FalsePositive)\n","    Recall = TruePositive / (TruePositive+FalseNegative)\n","\n","    print(\"Accuracy = \", Accuracy*100,\"%\")\n","    print(\"Specificity = \", Specificity*100,\"%\")\n","    print(\"Precision = \", Precision*100,\"%\")\n","    print(\"Recall = \", Recall*100,\"%\")\n","    return Accuracy*100, Precision*100, Specificity*100, Recall*100\n","\n","NonBindingMeta,NonBindingSequences,NonBindingCount = PreProcess(\"NotDNABinding.txt\")\n","#CAlls the PreProcess function to read the data from the given file and return the three relevant lists\n","BindingMeta,BindingSequences,BindingCount = PreProcess(\"DNABinding.txt\")\n","#Calls PreProcess to read data for binding Proteins and store them in three lists too\n","\n","NonBindingSequencesInt = ConvertToInt(NonBindingSequences)\n","BindingSequencesInt = ConvertToInt(BindingSequences)\n","#Calls the ConvertToInt on the sequences to convert letter codes to integer values\n","\n","if max(BindingCount) > max(NonBindingCount):\n","    #Only calls the function with the longest max length so they all get padded the same\n","    BindingSequencesInt, NonBindingSequencesInt = Pad(BindingSequencesInt, NonBindingSequencesInt, max(BindingCount))\n","else:\n","    BindingSequencesInt, NonBindingSequencesInt = Pad(BindingSequencesInt, NonBindingSequencesInt, max(NonBindingCount))\n","#Padds the integer sequences to even length 1000 or less\n","\n","TrainData,TrainLabels,ValData,ValLabels,TestData,TestLabels = Split(BindingSequencesInt, NonBindingSequencesInt)\n","#Calls the Split function to split the data int X and Y Train, Validate, and Test\n","print(\"Done\")#Update console of data being ready\n","#0 is non binding 1 is binding\n","\n","#Creating the model\n","#There are three kinds of Layers: Convolutional, Pooling and fully connected(or dense)\n","#Also the ReLU or Rectified Linear Unit layer. which houses the rectified linear activation function used for backpropogation of errors\n","#ReLU is a type of hidden layer, part of the dense or right before fully connected\n","#In My case I will begin with a Convolution layer and end with a dense fully connected layer\n","#the main body of the CNN will consist of one round of Batch Normalisation, then one of ReLU and an addition layer\n","#Input > Conv1D > Batch Norm > ReLU > Conv1D > Pooling > Dropout > Flatten > Dense\n","#Then Various other combinations will be attampted i.e.\n","#Input > Conv1D > Batch Norm > ReLU > Conv1D > Batch Norm > ReLU > Conv1D> Batch Norm > ReLU > Conv1D > Add > Pooling > Dropout > Flatten > Dense\n","\n","TrainX = to_categorical(TrainData)\n","ValX = to_categorical(ValData)\n","TestX = to_categorical(TestData)\n","\n","TrainY = to_categorical(TrainLabels)\n","ValY = to_categorical(ValLabels)\n","TestY = to_categorical(TestLabels)\n","\n","print(TrainX.shape,ValX.shape,TestX.shape)\n","print(TrainY.shape,ValY.shape,TestY.shape)\n","\n","\n","#Model1Input = Input(shape = (1000,22))#The shape of the input data, each AA chain is 1000x1 long with padding\n","#Model1Conv1 = Conv1D(50, 1, padding = 'same')(Model1Input)#Adds a second layer to the CNN, the 1D convolution layer\n","#Model1Batch1 = BatchNormalization()(Model1Conv1)#Adds a BAtchNormalisation Layer\n","#Model1ReLU = Activation('relu')(Model1Batch1)#Adds a ReLU activation function layer for backpropegation of errors and adjustment for later epochs\n","#Model1Conv2 = Conv1D(50, 1, padding = 'same', dilation_rate = 2, kernel_regularizer=l2(0.001))(Model1ReLU)#Second Convolutional Layer\n","#Model1Pool = MaxPooling1D(3)(Model1Conv2)#Pooling Layer\n","#Model1Dropout = Dropout(0.5)(Model1Pool)#Dropout Layer\n","#Model1Flatten = Flatten()(Model1Dropout)#Flatten the result of the previous layers to be parsed to the dense layer\n","#Model1Dense = Dense(2, activation = 'softmax', kernel_regularizer=l2(0.0001))(Model1Flatten)# D E N S E Layer. The main part of the CNN\n","\n","UndoneFilters = [45,50,55,60,65,70,75,80,85,90,95,100]\n","filters = [5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100]\n","batchSizes = [32,64,96,128,160,192,224,256,288,320,352,384,416,448,480,512]\n","#The best Epochs is 1500\n","\n","for fil in UndoneFilters:\n","  print(fil)\n","  ModelFirstInput = Input(shape = (1000,22))\n","  ModelFirstConv = Conv1D(fil,1, padding = 'same')(ModelFirstInput)\n","  ModelFirstPool = MaxPooling1D(3)(ModelFirstConv)\n","  ModelFirstDropout = Dropout(0.5)(ModelFirstPool)\n","  ModelFirstFlatten = Flatten()(ModelFirstDropout)\n","  ModelFirstDense = Dense(2, activation = 'softmax', kernel_regularizer=l2(0.0001))(ModelFirstFlatten)\n","  #Model1 = Model(inputs = Model1Input, outputs = Model1Dense)\n","  ModelFirst = Model(inputs = ModelFirstInput, outputs = ModelFirstDense)\n","\n","  ModelFirst.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","  ModelFirst.summary()\n","  FittedModelFirst = ModelFirst.fit(TrainX,TrainY,epochs=1500,batch_size=256,validation_data=(ValX,ValY))\n","  \n","  filepath = \"drive/My Drive/Project/Models/Model1_1500_fil_\"+str(fil)+\".h5\"\n","  ModelFirst.save(filepath)\n","\n","\n","#Solidifes the model as a model to be called and used from the first and last layers,\n","#Each layer parses to the next layer so has to have a readable output by the next layer\n","#The final layer categorises the data properly\n","\n","#Model1.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","#Compiles the Model\n","\n","EarlyCallback = EarlyStopping(monitor='val_loss',patience=3,verbose=1)\n","#Model1.summary()#Shows a summary of each layer, outputs, expecte inputs and parameters. Also the unique name\n","\n","\n","\n","#FittedModel1 = Model1.fit(TrainX,TrainY,epochs=2500,batch_size=256,validation_data=(ValX,ValY))#,callbacks=[EarlyCallback])\n","\n","#filepath = \"drive/My Drive/Project/Models/Model1_Final\"+str(epoch)+\".h5\"\n","#Model1.save(filepath)\n","#filepath = \"drive/My Drive/Project/Models/Model1_1250.h5\"\n","#Model1.save(filepath)\n","\n","#Predictions = Model1.predict_on_batch(TestX)\n","#epochAccuracy, epochPrecision, epochSpecificity, epochRecall = EvaluateModel(Predictions)\n","#accuracies.append(epochAccuracy)\n","#precisions.append(epochPrecision)\n","#specificities.append(epochSpecificity)\n","#recalls.append(epochRecall) \n","\n","#filepath = \"drive/My Drive/Project/Models/ModelFirst1250.h5\"\n","#ModelFirst = load_model(filepath)\n","\n","M_accuracies = []\n","M_precisions = []\n","M_specificities = []\n","M_recalls = []\n","\n","for fil in filters:\n","  filepath = \"drive/My Drive/Project/Models/Model1_1500_fil_\"+str(fil)+\".h5\"\n","  ModelFirst = load_model(filepath)\n","  Predictions = ModelFirst.predict_on_batch(TestX) \n","  epochAccuracy, epochPrecision, epochSpecificity, epochRecall = EvaluateModel(Predictions)\n","  M_accuracies.append(epochAccuracy)\n","  M_precisions.append(epochPrecision)\n","  M_specificities.append(epochSpecificity)\n","  M_recalls.append(epochRecall)\n","\n","print(M_accuracies)\n","print(M_precisions) \n","print(M_specificities) \n","print(M_recalls)\n","#Fitting the model to the Train and Validate Data. It's given the earlyCallback Callback which monitors 'loss' \n","  \n","  #It will return an display rate\n","  #filepath = \"drive/My Drive/Project/Models/Model1_\"+str(epoch)+\".h5\"\n","  #Model1 = load_model(filepath)\n","  #Model1.save(filepath)\n","  #new_model = load_model(filepath)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Padding Completed\n","Done\n","(10728, 1000, 22) (5364, 1000, 22) (1788, 1000, 22)\n","(10728, 2) (5364, 2) (1788, 2)\n","45\n","Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 1000, 22)]        0         \n","_________________________________________________________________\n","conv1d (Conv1D)              (None, 1000, 45)          1035      \n","_________________________________________________________________\n","max_pooling1d (MaxPooling1D) (None, 333, 45)           0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 333, 45)           0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 14985)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 2)                 29972     \n","=================================================================\n","Total params: 31,007\n","Trainable params: 31,007\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/1500\n","42/42 [==============================] - 2s 39ms/step - loss: 0.2290 - accuracy: 0.9539 - val_loss: 0.1407 - val_accuracy: 0.9681\n","Epoch 2/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.1358 - accuracy: 0.9680 - val_loss: 0.1268 - val_accuracy: 0.9681\n","Epoch 3/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.1239 - accuracy: 0.9680 - val_loss: 0.1173 - val_accuracy: 0.9681\n","Epoch 4/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.1113 - accuracy: 0.9679 - val_loss: 0.1111 - val_accuracy: 0.9679\n","Epoch 5/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.1036 - accuracy: 0.9686 - val_loss: 0.1064 - val_accuracy: 0.9683\n","Epoch 6/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0963 - accuracy: 0.9698 - val_loss: 0.1051 - val_accuracy: 0.9683\n","Epoch 7/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0889 - accuracy: 0.9712 - val_loss: 0.1016 - val_accuracy: 0.9676\n","Epoch 8/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0832 - accuracy: 0.9724 - val_loss: 0.1013 - val_accuracy: 0.9691\n","Epoch 9/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0776 - accuracy: 0.9738 - val_loss: 0.0986 - val_accuracy: 0.9694\n","Epoch 10/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0721 - accuracy: 0.9755 - val_loss: 0.1033 - val_accuracy: 0.9689\n","Epoch 11/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0685 - accuracy: 0.9766 - val_loss: 0.1023 - val_accuracy: 0.9691\n","Epoch 12/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0642 - accuracy: 0.9794 - val_loss: 0.1133 - val_accuracy: 0.9681\n","Epoch 13/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0610 - accuracy: 0.9797 - val_loss: 0.1021 - val_accuracy: 0.9696\n","Epoch 14/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0593 - accuracy: 0.9807 - val_loss: 0.0989 - val_accuracy: 0.9692\n","Epoch 15/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0544 - accuracy: 0.9819 - val_loss: 0.1026 - val_accuracy: 0.9700\n","Epoch 16/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0525 - accuracy: 0.9836 - val_loss: 0.1111 - val_accuracy: 0.9694\n","Epoch 17/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0478 - accuracy: 0.9855 - val_loss: 0.1026 - val_accuracy: 0.9687\n","Epoch 18/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0467 - accuracy: 0.9851 - val_loss: 0.1027 - val_accuracy: 0.9681\n","Epoch 19/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0448 - accuracy: 0.9881 - val_loss: 0.1131 - val_accuracy: 0.9692\n","Epoch 20/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0425 - accuracy: 0.9875 - val_loss: 0.1069 - val_accuracy: 0.9692\n","Epoch 21/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0384 - accuracy: 0.9887 - val_loss: 0.1083 - val_accuracy: 0.9692\n","Epoch 22/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0370 - accuracy: 0.9888 - val_loss: 0.1084 - val_accuracy: 0.9691\n","Epoch 23/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0363 - accuracy: 0.9898 - val_loss: 0.1169 - val_accuracy: 0.9700\n","Epoch 24/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0346 - accuracy: 0.9894 - val_loss: 0.1183 - val_accuracy: 0.9692\n","Epoch 25/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0343 - accuracy: 0.9897 - val_loss: 0.1209 - val_accuracy: 0.9698\n","Epoch 26/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0333 - accuracy: 0.9889 - val_loss: 0.1187 - val_accuracy: 0.9689\n","Epoch 27/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0331 - accuracy: 0.9906 - val_loss: 0.1151 - val_accuracy: 0.9677\n","Epoch 28/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0304 - accuracy: 0.9907 - val_loss: 0.1252 - val_accuracy: 0.9698\n","Epoch 29/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0292 - accuracy: 0.9919 - val_loss: 0.1238 - val_accuracy: 0.9694\n","Epoch 30/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0283 - accuracy: 0.9923 - val_loss: 0.1197 - val_accuracy: 0.9687\n","Epoch 31/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0293 - accuracy: 0.9922 - val_loss: 0.1228 - val_accuracy: 0.9687\n","Epoch 32/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0264 - accuracy: 0.9936 - val_loss: 0.1228 - val_accuracy: 0.9691\n","Epoch 33/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0291 - accuracy: 0.9918 - val_loss: 0.1378 - val_accuracy: 0.9700\n","Epoch 34/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0276 - accuracy: 0.9918 - val_loss: 0.1288 - val_accuracy: 0.9689\n","Epoch 35/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0253 - accuracy: 0.9927 - val_loss: 0.1328 - val_accuracy: 0.9687\n","Epoch 36/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 0.1303 - val_accuracy: 0.9677\n","Epoch 37/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0263 - accuracy: 0.9920 - val_loss: 0.1301 - val_accuracy: 0.9677\n","Epoch 38/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0239 - accuracy: 0.9948 - val_loss: 0.1324 - val_accuracy: 0.9694\n","Epoch 39/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0236 - accuracy: 0.9934 - val_loss: 0.1296 - val_accuracy: 0.9677\n","Epoch 40/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0232 - accuracy: 0.9936 - val_loss: 0.1354 - val_accuracy: 0.9689\n","Epoch 41/1500\n","42/42 [==============================] - 1s 30ms/step - loss: 0.0237 - accuracy: 0.9935 - val_loss: 0.1407 - val_accuracy: 0.9698\n","Epoch 42/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0213 - accuracy: 0.9947 - val_loss: 0.1448 - val_accuracy: 0.9692\n","Epoch 43/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.1392 - val_accuracy: 0.9679\n","Epoch 44/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 0.1390 - val_accuracy: 0.9683\n","Epoch 45/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0196 - accuracy: 0.9952 - val_loss: 0.1492 - val_accuracy: 0.9698\n","Epoch 46/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0208 - accuracy: 0.9947 - val_loss: 0.1451 - val_accuracy: 0.9689\n","Epoch 47/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0227 - accuracy: 0.9936 - val_loss: 0.1492 - val_accuracy: 0.9696\n","Epoch 48/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0226 - accuracy: 0.9940 - val_loss: 0.1441 - val_accuracy: 0.9679\n","Epoch 49/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0211 - accuracy: 0.9947 - val_loss: 0.1572 - val_accuracy: 0.9696\n","Epoch 50/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0213 - accuracy: 0.9946 - val_loss: 0.1506 - val_accuracy: 0.9685\n","Epoch 51/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0202 - accuracy: 0.9948 - val_loss: 0.1419 - val_accuracy: 0.9668\n","Epoch 52/1500\n","42/42 [==============================] - 1s 30ms/step - loss: 0.0192 - accuracy: 0.9948 - val_loss: 0.1479 - val_accuracy: 0.9681\n","Epoch 53/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0206 - accuracy: 0.9948 - val_loss: 0.1484 - val_accuracy: 0.9685\n","Epoch 54/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0194 - accuracy: 0.9957 - val_loss: 0.1514 - val_accuracy: 0.9685\n","Epoch 55/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0209 - accuracy: 0.9945 - val_loss: 0.1478 - val_accuracy: 0.9676\n","Epoch 56/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0169 - accuracy: 0.9966 - val_loss: 0.1578 - val_accuracy: 0.9692\n","Epoch 57/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0204 - accuracy: 0.9949 - val_loss: 0.1508 - val_accuracy: 0.9676\n","Epoch 58/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0195 - accuracy: 0.9952 - val_loss: 0.1623 - val_accuracy: 0.9696\n","Epoch 59/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0192 - accuracy: 0.9952 - val_loss: 0.1610 - val_accuracy: 0.9698\n","Epoch 60/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0204 - accuracy: 0.9949 - val_loss: 0.1545 - val_accuracy: 0.9683\n","Epoch 61/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0185 - accuracy: 0.9952 - val_loss: 0.1574 - val_accuracy: 0.9692\n","Epoch 62/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0185 - accuracy: 0.9949 - val_loss: 0.1511 - val_accuracy: 0.9677\n","Epoch 63/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0178 - accuracy: 0.9960 - val_loss: 0.1541 - val_accuracy: 0.9683\n","Epoch 64/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0179 - accuracy: 0.9954 - val_loss: 0.1686 - val_accuracy: 0.9696\n","Epoch 65/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0175 - accuracy: 0.9957 - val_loss: 0.1639 - val_accuracy: 0.9691\n","Epoch 66/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0178 - accuracy: 0.9956 - val_loss: 0.1604 - val_accuracy: 0.9687\n","Epoch 67/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0181 - accuracy: 0.9957 - val_loss: 0.1647 - val_accuracy: 0.9696\n","Epoch 68/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0181 - accuracy: 0.9961 - val_loss: 0.1626 - val_accuracy: 0.9692\n","Epoch 69/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.1709 - val_accuracy: 0.9694\n","Epoch 70/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0196 - accuracy: 0.9950 - val_loss: 0.1704 - val_accuracy: 0.9691\n","Epoch 71/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0200 - accuracy: 0.9949 - val_loss: 0.1820 - val_accuracy: 0.9702\n","Epoch 72/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.1632 - val_accuracy: 0.9679\n","Epoch 73/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 0.1648 - val_accuracy: 0.9677\n","Epoch 74/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0182 - accuracy: 0.9955 - val_loss: 0.1706 - val_accuracy: 0.9683\n","Epoch 75/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0176 - accuracy: 0.9958 - val_loss: 0.1707 - val_accuracy: 0.9691\n","Epoch 76/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0176 - accuracy: 0.9957 - val_loss: 0.1739 - val_accuracy: 0.9700\n","Epoch 77/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0172 - accuracy: 0.9964 - val_loss: 0.1756 - val_accuracy: 0.9696\n","Epoch 78/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0172 - accuracy: 0.9964 - val_loss: 0.1810 - val_accuracy: 0.9696\n","Epoch 79/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 0.1692 - val_accuracy: 0.9681\n","Epoch 80/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0178 - accuracy: 0.9960 - val_loss: 0.1753 - val_accuracy: 0.9689\n","Epoch 81/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0197 - accuracy: 0.9952 - val_loss: 0.1710 - val_accuracy: 0.9685\n","Epoch 82/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0171 - accuracy: 0.9957 - val_loss: 0.1666 - val_accuracy: 0.9674\n","Epoch 83/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0188 - accuracy: 0.9954 - val_loss: 0.1751 - val_accuracy: 0.9681\n","Epoch 84/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0179 - accuracy: 0.9956 - val_loss: 0.1774 - val_accuracy: 0.9683\n","Epoch 85/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0164 - accuracy: 0.9960 - val_loss: 0.1689 - val_accuracy: 0.9672\n","Epoch 86/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0193 - accuracy: 0.9957 - val_loss: 0.1720 - val_accuracy: 0.9681\n","Epoch 87/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0180 - accuracy: 0.9954 - val_loss: 0.1878 - val_accuracy: 0.9696\n","Epoch 88/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0172 - accuracy: 0.9968 - val_loss: 0.1983 - val_accuracy: 0.9696\n","Epoch 89/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0168 - accuracy: 0.9960 - val_loss: 0.1902 - val_accuracy: 0.9700\n","Epoch 90/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0170 - accuracy: 0.9962 - val_loss: 0.1766 - val_accuracy: 0.9681\n","Epoch 91/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0187 - accuracy: 0.9960 - val_loss: 0.1777 - val_accuracy: 0.9683\n","Epoch 92/1500\n","42/42 [==============================] - 1s 30ms/step - loss: 0.0179 - accuracy: 0.9957 - val_loss: 0.1773 - val_accuracy: 0.9679\n","Epoch 93/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0165 - accuracy: 0.9961 - val_loss: 0.1809 - val_accuracy: 0.9681\n","Epoch 94/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0159 - accuracy: 0.9967 - val_loss: 0.1755 - val_accuracy: 0.9677\n","Epoch 95/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0182 - accuracy: 0.9956 - val_loss: 0.1780 - val_accuracy: 0.9681\n","Epoch 96/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0185 - accuracy: 0.9961 - val_loss: 0.1765 - val_accuracy: 0.9679\n","Epoch 97/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0162 - accuracy: 0.9961 - val_loss: 0.1861 - val_accuracy: 0.9689\n","Epoch 98/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0158 - accuracy: 0.9971 - val_loss: 0.1783 - val_accuracy: 0.9683\n","Epoch 99/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0156 - accuracy: 0.9968 - val_loss: 0.1997 - val_accuracy: 0.9711\n","Epoch 100/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0175 - accuracy: 0.9966 - val_loss: 0.1771 - val_accuracy: 0.9676\n","Epoch 101/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0164 - accuracy: 0.9966 - val_loss: 0.1779 - val_accuracy: 0.9668\n","Epoch 102/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0161 - accuracy: 0.9963 - val_loss: 0.1903 - val_accuracy: 0.9696\n","Epoch 103/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0181 - accuracy: 0.9958 - val_loss: 0.1953 - val_accuracy: 0.9702\n","Epoch 104/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0170 - accuracy: 0.9965 - val_loss: 0.1975 - val_accuracy: 0.9702\n","Epoch 105/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0175 - accuracy: 0.9965 - val_loss: 0.1885 - val_accuracy: 0.9689\n","Epoch 106/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0176 - accuracy: 0.9963 - val_loss: 0.1906 - val_accuracy: 0.9692\n","Epoch 107/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0159 - accuracy: 0.9967 - val_loss: 0.1862 - val_accuracy: 0.9676\n","Epoch 108/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0162 - accuracy: 0.9964 - val_loss: 0.1812 - val_accuracy: 0.9677\n","Epoch 109/1500\n","42/42 [==============================] - 2s 37ms/step - loss: 0.0185 - accuracy: 0.9955 - val_loss: 0.1922 - val_accuracy: 0.9689\n","Epoch 110/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0160 - accuracy: 0.9967 - val_loss: 0.1894 - val_accuracy: 0.9687\n","Epoch 111/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 0.1960 - val_accuracy: 0.9696\n","Epoch 112/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0156 - accuracy: 0.9966 - val_loss: 0.1855 - val_accuracy: 0.9681\n","Epoch 113/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0176 - accuracy: 0.9959 - val_loss: 0.1943 - val_accuracy: 0.9691\n","Epoch 114/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0158 - accuracy: 0.9965 - val_loss: 0.1905 - val_accuracy: 0.9683\n","Epoch 115/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0170 - accuracy: 0.9967 - val_loss: 0.1839 - val_accuracy: 0.9670\n","Epoch 116/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0191 - accuracy: 0.9954 - val_loss: 0.1992 - val_accuracy: 0.9702\n","Epoch 117/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0162 - accuracy: 0.9962 - val_loss: 0.1842 - val_accuracy: 0.9689\n","Epoch 118/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 0.1996 - val_accuracy: 0.9707\n","Epoch 119/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0182 - accuracy: 0.9963 - val_loss: 0.1966 - val_accuracy: 0.9709\n","Epoch 120/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.1978 - val_accuracy: 0.9702\n","Epoch 121/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0156 - accuracy: 0.9972 - val_loss: 0.1927 - val_accuracy: 0.9694\n","Epoch 122/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0168 - accuracy: 0.9964 - val_loss: 0.1996 - val_accuracy: 0.9694\n","Epoch 123/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0156 - accuracy: 0.9968 - val_loss: 0.1861 - val_accuracy: 0.9672\n","Epoch 124/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0166 - accuracy: 0.9963 - val_loss: 0.1800 - val_accuracy: 0.9661\n","Epoch 125/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0168 - accuracy: 0.9961 - val_loss: 0.1953 - val_accuracy: 0.9677\n","Epoch 126/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0168 - accuracy: 0.9965 - val_loss: 0.2023 - val_accuracy: 0.9700\n","Epoch 127/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0157 - accuracy: 0.9975 - val_loss: 0.1965 - val_accuracy: 0.9685\n","Epoch 128/1500\n","42/42 [==============================] - 1s 34ms/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.1977 - val_accuracy: 0.9689\n","Epoch 129/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0156 - accuracy: 0.9972 - val_loss: 0.1902 - val_accuracy: 0.9681\n","Epoch 130/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0183 - accuracy: 0.9961 - val_loss: 0.2053 - val_accuracy: 0.9700\n","Epoch 131/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0173 - accuracy: 0.9968 - val_loss: 0.1892 - val_accuracy: 0.9694\n","Epoch 132/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0179 - accuracy: 0.9959 - val_loss: 0.1859 - val_accuracy: 0.9691\n","Epoch 133/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.1826 - val_accuracy: 0.9689\n","Epoch 134/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0179 - accuracy: 0.9964 - val_loss: 0.2057 - val_accuracy: 0.9696\n","Epoch 135/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0172 - accuracy: 0.9969 - val_loss: 0.2092 - val_accuracy: 0.9705\n","Epoch 136/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0158 - accuracy: 0.9968 - val_loss: 0.1916 - val_accuracy: 0.9685\n","Epoch 137/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0171 - accuracy: 0.9960 - val_loss: 0.1968 - val_accuracy: 0.9681\n","Epoch 138/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0160 - accuracy: 0.9973 - val_loss: 0.1902 - val_accuracy: 0.9670\n","Epoch 139/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 0.1975 - val_accuracy: 0.9691\n","Epoch 140/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0158 - accuracy: 0.9970 - val_loss: 0.1951 - val_accuracy: 0.9674\n","Epoch 141/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0156 - accuracy: 0.9961 - val_loss: 0.2083 - val_accuracy: 0.9689\n","Epoch 142/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0148 - accuracy: 0.9972 - val_loss: 0.2091 - val_accuracy: 0.9687\n","Epoch 143/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 0.2309 - val_accuracy: 0.9705\n","Epoch 144/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0178 - accuracy: 0.9955 - val_loss: 0.2069 - val_accuracy: 0.9694\n","Epoch 145/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0144 - accuracy: 0.9975 - val_loss: 0.1966 - val_accuracy: 0.9674\n","Epoch 146/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0166 - accuracy: 0.9964 - val_loss: 0.1931 - val_accuracy: 0.9679\n","Epoch 147/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0162 - accuracy: 0.9973 - val_loss: 0.2138 - val_accuracy: 0.9698\n","Epoch 148/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0156 - accuracy: 0.9971 - val_loss: 0.2009 - val_accuracy: 0.9683\n","Epoch 149/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9976 - val_loss: 0.1995 - val_accuracy: 0.9681\n","Epoch 150/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0150 - accuracy: 0.9971 - val_loss: 0.2123 - val_accuracy: 0.9691\n","Epoch 151/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.1977 - val_accuracy: 0.9676\n","Epoch 152/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0151 - accuracy: 0.9973 - val_loss: 0.1959 - val_accuracy: 0.9679\n","Epoch 153/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0159 - accuracy: 0.9971 - val_loss: 0.2150 - val_accuracy: 0.9687\n","Epoch 154/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0167 - accuracy: 0.9966 - val_loss: 0.2045 - val_accuracy: 0.9679\n","Epoch 155/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0153 - accuracy: 0.9968 - val_loss: 0.1995 - val_accuracy: 0.9683\n","Epoch 156/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0148 - accuracy: 0.9971 - val_loss: 0.2038 - val_accuracy: 0.9679\n","Epoch 157/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0173 - accuracy: 0.9962 - val_loss: 0.1942 - val_accuracy: 0.9676\n","Epoch 158/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0171 - accuracy: 0.9964 - val_loss: 0.2052 - val_accuracy: 0.9687\n","Epoch 159/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0154 - accuracy: 0.9976 - val_loss: 0.2124 - val_accuracy: 0.9696\n","Epoch 160/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0178 - accuracy: 0.9962 - val_loss: 0.1955 - val_accuracy: 0.9687\n","Epoch 161/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.1953 - val_accuracy: 0.9687\n","Epoch 162/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0196 - accuracy: 0.9958 - val_loss: 0.2287 - val_accuracy: 0.9709\n","Epoch 163/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0185 - accuracy: 0.9964 - val_loss: 0.1944 - val_accuracy: 0.9685\n","Epoch 164/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0165 - accuracy: 0.9966 - val_loss: 0.2062 - val_accuracy: 0.9707\n","Epoch 165/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0159 - accuracy: 0.9967 - val_loss: 0.2011 - val_accuracy: 0.9700\n","Epoch 166/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0148 - accuracy: 0.9974 - val_loss: 0.1953 - val_accuracy: 0.9696\n","Epoch 167/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.1921 - val_accuracy: 0.9685\n","Epoch 168/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0173 - accuracy: 0.9962 - val_loss: 0.2022 - val_accuracy: 0.9709\n","Epoch 169/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0154 - accuracy: 0.9968 - val_loss: 0.2089 - val_accuracy: 0.9718\n","Epoch 170/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0177 - accuracy: 0.9962 - val_loss: 0.2122 - val_accuracy: 0.9717\n","Epoch 171/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0166 - accuracy: 0.9964 - val_loss: 0.2093 - val_accuracy: 0.9711\n","Epoch 172/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 0.2010 - val_accuracy: 0.9705\n","Epoch 173/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0168 - accuracy: 0.9964 - val_loss: 0.2001 - val_accuracy: 0.9705\n","Epoch 174/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0182 - accuracy: 0.9962 - val_loss: 0.1995 - val_accuracy: 0.9702\n","Epoch 175/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0172 - accuracy: 0.9970 - val_loss: 0.1986 - val_accuracy: 0.9696\n","Epoch 176/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0151 - accuracy: 0.9974 - val_loss: 0.2158 - val_accuracy: 0.9705\n","Epoch 177/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 0.1973 - val_accuracy: 0.9689\n","Epoch 178/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0160 - accuracy: 0.9970 - val_loss: 0.2084 - val_accuracy: 0.9700\n","Epoch 179/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0172 - accuracy: 0.9964 - val_loss: 0.1990 - val_accuracy: 0.9685\n","Epoch 180/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 0.2040 - val_accuracy: 0.9698\n","Epoch 181/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0160 - accuracy: 0.9966 - val_loss: 0.1967 - val_accuracy: 0.9687\n","Epoch 182/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0172 - accuracy: 0.9964 - val_loss: 0.2052 - val_accuracy: 0.9694\n","Epoch 183/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0155 - accuracy: 0.9973 - val_loss: 0.1914 - val_accuracy: 0.9677\n","Epoch 184/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0189 - accuracy: 0.9956 - val_loss: 0.2031 - val_accuracy: 0.9691\n","Epoch 185/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0169 - accuracy: 0.9964 - val_loss: 0.2022 - val_accuracy: 0.9694\n","Epoch 186/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.2095 - val_accuracy: 0.9705\n","Epoch 187/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0163 - accuracy: 0.9971 - val_loss: 0.2104 - val_accuracy: 0.9702\n","Epoch 188/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0177 - accuracy: 0.9958 - val_loss: 0.2033 - val_accuracy: 0.9691\n","Epoch 189/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0162 - accuracy: 0.9967 - val_loss: 0.1985 - val_accuracy: 0.9683\n","Epoch 190/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0158 - accuracy: 0.9974 - val_loss: 0.2009 - val_accuracy: 0.9694\n","Epoch 191/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0153 - accuracy: 0.9975 - val_loss: 0.2080 - val_accuracy: 0.9704\n","Epoch 192/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0151 - accuracy: 0.9972 - val_loss: 0.2101 - val_accuracy: 0.9707\n","Epoch 193/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0155 - accuracy: 0.9973 - val_loss: 0.2027 - val_accuracy: 0.9696\n","Epoch 194/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0158 - accuracy: 0.9967 - val_loss: 0.2027 - val_accuracy: 0.9700\n","Epoch 195/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0166 - accuracy: 0.9973 - val_loss: 0.2014 - val_accuracy: 0.9694\n","Epoch 196/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0158 - accuracy: 0.9970 - val_loss: 0.2093 - val_accuracy: 0.9702\n","Epoch 197/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0149 - accuracy: 0.9972 - val_loss: 0.2063 - val_accuracy: 0.9704\n","Epoch 198/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0155 - accuracy: 0.9967 - val_loss: 0.1977 - val_accuracy: 0.9694\n","Epoch 199/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0152 - accuracy: 0.9975 - val_loss: 0.2231 - val_accuracy: 0.9709\n","Epoch 200/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0176 - accuracy: 0.9964 - val_loss: 0.2074 - val_accuracy: 0.9696\n","Epoch 201/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0171 - accuracy: 0.9965 - val_loss: 0.2084 - val_accuracy: 0.9705\n","Epoch 202/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0157 - accuracy: 0.9971 - val_loss: 0.1967 - val_accuracy: 0.9694\n","Epoch 203/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0167 - accuracy: 0.9967 - val_loss: 0.2001 - val_accuracy: 0.9704\n","Epoch 204/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0145 - accuracy: 0.9980 - val_loss: 0.1966 - val_accuracy: 0.9704\n","Epoch 205/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.2126 - val_accuracy: 0.9707\n","Epoch 206/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0150 - accuracy: 0.9975 - val_loss: 0.2098 - val_accuracy: 0.9702\n","Epoch 207/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0166 - accuracy: 0.9962 - val_loss: 0.2129 - val_accuracy: 0.9704\n","Epoch 208/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.2083 - val_accuracy: 0.9692\n","Epoch 209/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0154 - accuracy: 0.9974 - val_loss: 0.1928 - val_accuracy: 0.9698\n","Epoch 210/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0143 - accuracy: 0.9975 - val_loss: 0.2120 - val_accuracy: 0.9698\n","Epoch 211/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0149 - accuracy: 0.9978 - val_loss: 0.2262 - val_accuracy: 0.9717\n","Epoch 212/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0164 - accuracy: 0.9967 - val_loss: 0.2126 - val_accuracy: 0.9704\n","Epoch 213/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0134 - accuracy: 0.9980 - val_loss: 0.2065 - val_accuracy: 0.9694\n","Epoch 214/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0172 - accuracy: 0.9966 - val_loss: 0.2078 - val_accuracy: 0.9705\n","Epoch 215/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0146 - accuracy: 0.9978 - val_loss: 0.2063 - val_accuracy: 0.9702\n","Epoch 216/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0169 - accuracy: 0.9967 - val_loss: 0.2300 - val_accuracy: 0.9715\n","Epoch 217/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0166 - accuracy: 0.9966 - val_loss: 0.2038 - val_accuracy: 0.9705\n","Epoch 218/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0150 - accuracy: 0.9973 - val_loss: 0.1986 - val_accuracy: 0.9705\n","Epoch 219/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0161 - accuracy: 0.9971 - val_loss: 0.2090 - val_accuracy: 0.9711\n","Epoch 220/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0147 - accuracy: 0.9978 - val_loss: 0.2143 - val_accuracy: 0.9711\n","Epoch 221/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0147 - accuracy: 0.9973 - val_loss: 0.1993 - val_accuracy: 0.9707\n","Epoch 222/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0163 - accuracy: 0.9964 - val_loss: 0.1950 - val_accuracy: 0.9698\n","Epoch 223/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0157 - accuracy: 0.9970 - val_loss: 0.2289 - val_accuracy: 0.9715\n","Epoch 224/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0136 - accuracy: 0.9978 - val_loss: 0.2192 - val_accuracy: 0.9715\n","Epoch 225/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0158 - accuracy: 0.9968 - val_loss: 0.1985 - val_accuracy: 0.9709\n","Epoch 226/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0146 - accuracy: 0.9978 - val_loss: 0.2076 - val_accuracy: 0.9713\n","Epoch 227/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0150 - accuracy: 0.9968 - val_loss: 0.2103 - val_accuracy: 0.9713\n","Epoch 228/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0150 - accuracy: 0.9974 - val_loss: 0.2035 - val_accuracy: 0.9705\n","Epoch 229/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0136 - accuracy: 0.9979 - val_loss: 0.2107 - val_accuracy: 0.9715\n","Epoch 230/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 0.1956 - val_accuracy: 0.9692\n","Epoch 231/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0141 - accuracy: 0.9973 - val_loss: 0.2007 - val_accuracy: 0.9696\n","Epoch 232/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0158 - accuracy: 0.9967 - val_loss: 0.1945 - val_accuracy: 0.9696\n","Epoch 233/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0159 - accuracy: 0.9970 - val_loss: 0.2000 - val_accuracy: 0.9704\n","Epoch 234/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0171 - accuracy: 0.9967 - val_loss: 0.2088 - val_accuracy: 0.9711\n","Epoch 235/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.2043 - val_accuracy: 0.9713\n","Epoch 236/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.2095 - val_accuracy: 0.9718\n","Epoch 237/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0143 - accuracy: 0.9970 - val_loss: 0.1981 - val_accuracy: 0.9715\n","Epoch 238/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0163 - accuracy: 0.9966 - val_loss: 0.2068 - val_accuracy: 0.9715\n","Epoch 239/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0176 - accuracy: 0.9968 - val_loss: 0.2042 - val_accuracy: 0.9715\n","Epoch 240/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.2049 - val_accuracy: 0.9717\n","Epoch 241/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0155 - accuracy: 0.9976 - val_loss: 0.2148 - val_accuracy: 0.9717\n","Epoch 242/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9978 - val_loss: 0.2080 - val_accuracy: 0.9705\n","Epoch 243/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.1967 - val_accuracy: 0.9700\n","Epoch 244/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0148 - accuracy: 0.9971 - val_loss: 0.2090 - val_accuracy: 0.9709\n","Epoch 245/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 0.2032 - val_accuracy: 0.9713\n","Epoch 246/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0134 - accuracy: 0.9980 - val_loss: 0.2046 - val_accuracy: 0.9713\n","Epoch 247/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0145 - accuracy: 0.9974 - val_loss: 0.2195 - val_accuracy: 0.9713\n","Epoch 248/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 0.2193 - val_accuracy: 0.9717\n","Epoch 249/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0148 - accuracy: 0.9974 - val_loss: 0.2072 - val_accuracy: 0.9715\n","Epoch 250/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0145 - accuracy: 0.9967 - val_loss: 0.2026 - val_accuracy: 0.9709\n","Epoch 251/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0154 - accuracy: 0.9970 - val_loss: 0.2099 - val_accuracy: 0.9717\n","Epoch 252/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.2080 - val_accuracy: 0.9715\n","Epoch 253/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0143 - accuracy: 0.9972 - val_loss: 0.1971 - val_accuracy: 0.9696\n","Epoch 254/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0166 - accuracy: 0.9975 - val_loss: 0.1924 - val_accuracy: 0.9687\n","Epoch 255/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0171 - accuracy: 0.9960 - val_loss: 0.2153 - val_accuracy: 0.9715\n","Epoch 256/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0150 - accuracy: 0.9970 - val_loss: 0.2140 - val_accuracy: 0.9715\n","Epoch 257/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0153 - accuracy: 0.9975 - val_loss: 0.2115 - val_accuracy: 0.9717\n","Epoch 258/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 0.2127 - val_accuracy: 0.9718\n","Epoch 259/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0147 - accuracy: 0.9977 - val_loss: 0.2199 - val_accuracy: 0.9709\n","Epoch 260/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0151 - accuracy: 0.9976 - val_loss: 0.2057 - val_accuracy: 0.9698\n","Epoch 261/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0155 - accuracy: 0.9974 - val_loss: 0.2102 - val_accuracy: 0.9705\n","Epoch 262/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0165 - accuracy: 0.9966 - val_loss: 0.1997 - val_accuracy: 0.9700\n","Epoch 263/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0147 - accuracy: 0.9978 - val_loss: 0.2089 - val_accuracy: 0.9704\n","Epoch 264/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0162 - accuracy: 0.9963 - val_loss: 0.2063 - val_accuracy: 0.9702\n","Epoch 265/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0150 - accuracy: 0.9974 - val_loss: 0.2136 - val_accuracy: 0.9702\n","Epoch 266/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0160 - accuracy: 0.9966 - val_loss: 0.2028 - val_accuracy: 0.9704\n","Epoch 267/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0147 - accuracy: 0.9975 - val_loss: 0.2091 - val_accuracy: 0.9717\n","Epoch 268/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0150 - accuracy: 0.9970 - val_loss: 0.2036 - val_accuracy: 0.9711\n","Epoch 269/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0156 - accuracy: 0.9964 - val_loss: 0.2220 - val_accuracy: 0.9715\n","Epoch 270/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 0.2214 - val_accuracy: 0.9713\n","Epoch 271/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 0.2118 - val_accuracy: 0.9709\n","Epoch 272/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0146 - accuracy: 0.9968 - val_loss: 0.2151 - val_accuracy: 0.9709\n","Epoch 273/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0164 - accuracy: 0.9966 - val_loss: 0.2144 - val_accuracy: 0.9709\n","Epoch 274/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0156 - accuracy: 0.9970 - val_loss: 0.2245 - val_accuracy: 0.9707\n","Epoch 275/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0139 - accuracy: 0.9977 - val_loss: 0.2200 - val_accuracy: 0.9707\n","Epoch 276/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.2282 - val_accuracy: 0.9709\n","Epoch 277/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.2017 - val_accuracy: 0.9689\n","Epoch 278/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0167 - accuracy: 0.9965 - val_loss: 0.2170 - val_accuracy: 0.9696\n","Epoch 279/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0160 - accuracy: 0.9967 - val_loss: 0.2048 - val_accuracy: 0.9683\n","Epoch 280/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0165 - accuracy: 0.9971 - val_loss: 0.2099 - val_accuracy: 0.9700\n","Epoch 281/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0156 - accuracy: 0.9972 - val_loss: 0.2144 - val_accuracy: 0.9700\n","Epoch 282/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0161 - accuracy: 0.9970 - val_loss: 0.2106 - val_accuracy: 0.9702\n","Epoch 283/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0156 - accuracy: 0.9974 - val_loss: 0.2178 - val_accuracy: 0.9705\n","Epoch 284/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0148 - accuracy: 0.9975 - val_loss: 0.2106 - val_accuracy: 0.9704\n","Epoch 285/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0151 - accuracy: 0.9968 - val_loss: 0.2302 - val_accuracy: 0.9713\n","Epoch 286/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0145 - accuracy: 0.9972 - val_loss: 0.2123 - val_accuracy: 0.9705\n","Epoch 287/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0167 - accuracy: 0.9964 - val_loss: 0.2330 - val_accuracy: 0.9715\n","Epoch 288/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.2074 - val_accuracy: 0.9696\n","Epoch 289/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 0.2074 - val_accuracy: 0.9702\n","Epoch 290/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0151 - accuracy: 0.9973 - val_loss: 0.2367 - val_accuracy: 0.9726\n","Epoch 291/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0141 - accuracy: 0.9977 - val_loss: 0.2123 - val_accuracy: 0.9705\n","Epoch 292/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0148 - accuracy: 0.9975 - val_loss: 0.2004 - val_accuracy: 0.9685\n","Epoch 293/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.2096 - val_accuracy: 0.9704\n","Epoch 294/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0154 - accuracy: 0.9973 - val_loss: 0.2069 - val_accuracy: 0.9707\n","Epoch 295/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0149 - accuracy: 0.9973 - val_loss: 0.2031 - val_accuracy: 0.9704\n","Epoch 296/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0170 - accuracy: 0.9968 - val_loss: 0.2266 - val_accuracy: 0.9709\n","Epoch 297/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.1999 - val_accuracy: 0.9700\n","Epoch 298/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0154 - accuracy: 0.9970 - val_loss: 0.2258 - val_accuracy: 0.9705\n","Epoch 299/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0157 - accuracy: 0.9967 - val_loss: 0.2050 - val_accuracy: 0.9704\n","Epoch 300/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0168 - accuracy: 0.9963 - val_loss: 0.2051 - val_accuracy: 0.9696\n","Epoch 301/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0171 - accuracy: 0.9966 - val_loss: 0.2238 - val_accuracy: 0.9702\n","Epoch 302/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0158 - accuracy: 0.9966 - val_loss: 0.2136 - val_accuracy: 0.9705\n","Epoch 303/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0157 - accuracy: 0.9972 - val_loss: 0.2099 - val_accuracy: 0.9705\n","Epoch 304/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0149 - accuracy: 0.9973 - val_loss: 0.2071 - val_accuracy: 0.9704\n","Epoch 305/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9979 - val_loss: 0.2058 - val_accuracy: 0.9702\n","Epoch 306/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0156 - accuracy: 0.9971 - val_loss: 0.2210 - val_accuracy: 0.9707\n","Epoch 307/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0136 - accuracy: 0.9980 - val_loss: 0.2146 - val_accuracy: 0.9707\n","Epoch 308/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0140 - accuracy: 0.9978 - val_loss: 0.2170 - val_accuracy: 0.9704\n","Epoch 309/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0141 - accuracy: 0.9978 - val_loss: 0.2243 - val_accuracy: 0.9711\n","Epoch 310/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0142 - accuracy: 0.9975 - val_loss: 0.2262 - val_accuracy: 0.9713\n","Epoch 311/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0141 - accuracy: 0.9978 - val_loss: 0.2162 - val_accuracy: 0.9705\n","Epoch 312/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0146 - accuracy: 0.9973 - val_loss: 0.2052 - val_accuracy: 0.9698\n","Epoch 313/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0155 - accuracy: 0.9975 - val_loss: 0.2224 - val_accuracy: 0.9707\n","Epoch 314/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0144 - accuracy: 0.9974 - val_loss: 0.2068 - val_accuracy: 0.9704\n","Epoch 315/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0140 - accuracy: 0.9976 - val_loss: 0.2225 - val_accuracy: 0.9713\n","Epoch 316/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0134 - accuracy: 0.9985 - val_loss: 0.2052 - val_accuracy: 0.9694\n","Epoch 317/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0153 - accuracy: 0.9968 - val_loss: 0.2098 - val_accuracy: 0.9700\n","Epoch 318/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0153 - accuracy: 0.9970 - val_loss: 0.2189 - val_accuracy: 0.9711\n","Epoch 319/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0146 - accuracy: 0.9973 - val_loss: 0.2222 - val_accuracy: 0.9709\n","Epoch 320/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0150 - accuracy: 0.9973 - val_loss: 0.2161 - val_accuracy: 0.9715\n","Epoch 321/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0171 - accuracy: 0.9966 - val_loss: 0.2173 - val_accuracy: 0.9711\n","Epoch 322/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0155 - accuracy: 0.9978 - val_loss: 0.2148 - val_accuracy: 0.9713\n","Epoch 323/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0147 - accuracy: 0.9973 - val_loss: 0.2037 - val_accuracy: 0.9698\n","Epoch 324/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0143 - accuracy: 0.9976 - val_loss: 0.2129 - val_accuracy: 0.9704\n","Epoch 325/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0140 - accuracy: 0.9979 - val_loss: 0.2068 - val_accuracy: 0.9707\n","Epoch 326/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0140 - accuracy: 0.9976 - val_loss: 0.2130 - val_accuracy: 0.9707\n","Epoch 327/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0163 - accuracy: 0.9967 - val_loss: 0.2106 - val_accuracy: 0.9705\n","Epoch 328/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0128 - accuracy: 0.9978 - val_loss: 0.2269 - val_accuracy: 0.9715\n","Epoch 329/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9981 - val_loss: 0.2117 - val_accuracy: 0.9707\n","Epoch 330/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0116 - accuracy: 0.9988 - val_loss: 0.2003 - val_accuracy: 0.9694\n","Epoch 331/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 0.2363 - val_accuracy: 0.9718\n","Epoch 332/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.2036 - val_accuracy: 0.9713\n","Epoch 333/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0147 - accuracy: 0.9970 - val_loss: 0.2128 - val_accuracy: 0.9705\n","Epoch 334/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0141 - accuracy: 0.9976 - val_loss: 0.2127 - val_accuracy: 0.9704\n","Epoch 335/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0148 - accuracy: 0.9972 - val_loss: 0.2175 - val_accuracy: 0.9704\n","Epoch 336/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0145 - accuracy: 0.9974 - val_loss: 0.2109 - val_accuracy: 0.9700\n","Epoch 337/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0145 - accuracy: 0.9971 - val_loss: 0.2257 - val_accuracy: 0.9705\n","Epoch 338/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0151 - accuracy: 0.9973 - val_loss: 0.2178 - val_accuracy: 0.9717\n","Epoch 339/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0146 - accuracy: 0.9973 - val_loss: 0.2192 - val_accuracy: 0.9718\n","Epoch 340/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0139 - accuracy: 0.9977 - val_loss: 0.2123 - val_accuracy: 0.9709\n","Epoch 341/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0144 - accuracy: 0.9974 - val_loss: 0.2241 - val_accuracy: 0.9713\n","Epoch 342/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9978 - val_loss: 0.2128 - val_accuracy: 0.9700\n","Epoch 343/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0149 - accuracy: 0.9970 - val_loss: 0.2241 - val_accuracy: 0.9720\n","Epoch 344/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0134 - accuracy: 0.9976 - val_loss: 0.2235 - val_accuracy: 0.9724\n","Epoch 345/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0132 - accuracy: 0.9975 - val_loss: 0.2209 - val_accuracy: 0.9717\n","Epoch 346/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0150 - accuracy: 0.9973 - val_loss: 0.2169 - val_accuracy: 0.9707\n","Epoch 347/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.2120 - val_accuracy: 0.9707\n","Epoch 348/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9977 - val_loss: 0.2090 - val_accuracy: 0.9707\n","Epoch 349/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0154 - accuracy: 0.9962 - val_loss: 0.2076 - val_accuracy: 0.9694\n","Epoch 350/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0158 - accuracy: 0.9967 - val_loss: 0.2209 - val_accuracy: 0.9704\n","Epoch 351/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0145 - accuracy: 0.9974 - val_loss: 0.2128 - val_accuracy: 0.9704\n","Epoch 352/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0164 - accuracy: 0.9966 - val_loss: 0.2172 - val_accuracy: 0.9700\n","Epoch 353/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0148 - accuracy: 0.9977 - val_loss: 0.2225 - val_accuracy: 0.9704\n","Epoch 354/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0152 - accuracy: 0.9975 - val_loss: 0.2114 - val_accuracy: 0.9691\n","Epoch 355/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0165 - accuracy: 0.9965 - val_loss: 0.2207 - val_accuracy: 0.9702\n","Epoch 356/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0154 - accuracy: 0.9975 - val_loss: 0.2339 - val_accuracy: 0.9717\n","Epoch 357/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0145 - accuracy: 0.9970 - val_loss: 0.2367 - val_accuracy: 0.9711\n","Epoch 358/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0165 - accuracy: 0.9966 - val_loss: 0.2189 - val_accuracy: 0.9705\n","Epoch 359/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9982 - val_loss: 0.2183 - val_accuracy: 0.9704\n","Epoch 360/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0158 - accuracy: 0.9972 - val_loss: 0.2040 - val_accuracy: 0.9691\n","Epoch 361/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 0.2189 - val_accuracy: 0.9705\n","Epoch 362/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0155 - accuracy: 0.9971 - val_loss: 0.2259 - val_accuracy: 0.9718\n","Epoch 363/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0149 - accuracy: 0.9975 - val_loss: 0.2075 - val_accuracy: 0.9704\n","Epoch 364/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9975 - val_loss: 0.2198 - val_accuracy: 0.9711\n","Epoch 365/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0155 - accuracy: 0.9975 - val_loss: 0.2238 - val_accuracy: 0.9707\n","Epoch 366/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9978 - val_loss: 0.2012 - val_accuracy: 0.9698\n","Epoch 367/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0152 - accuracy: 0.9968 - val_loss: 0.2315 - val_accuracy: 0.9718\n","Epoch 368/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0153 - accuracy: 0.9974 - val_loss: 0.2214 - val_accuracy: 0.9704\n","Epoch 369/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0149 - accuracy: 0.9973 - val_loss: 0.2332 - val_accuracy: 0.9715\n","Epoch 370/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0160 - accuracy: 0.9965 - val_loss: 0.2159 - val_accuracy: 0.9715\n","Epoch 371/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 0.2187 - val_accuracy: 0.9709\n","Epoch 372/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0135 - accuracy: 0.9979 - val_loss: 0.2201 - val_accuracy: 0.9711\n","Epoch 373/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.2215 - val_accuracy: 0.9720\n","Epoch 374/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0143 - accuracy: 0.9976 - val_loss: 0.2170 - val_accuracy: 0.9702\n","Epoch 375/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9979 - val_loss: 0.2180 - val_accuracy: 0.9704\n","Epoch 376/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0134 - accuracy: 0.9975 - val_loss: 0.2068 - val_accuracy: 0.9705\n","Epoch 377/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0157 - accuracy: 0.9972 - val_loss: 0.2329 - val_accuracy: 0.9715\n","Epoch 378/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.2093 - val_accuracy: 0.9704\n","Epoch 379/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.2039 - val_accuracy: 0.9711\n","Epoch 380/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0144 - accuracy: 0.9973 - val_loss: 0.2370 - val_accuracy: 0.9722\n","Epoch 381/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0158 - accuracy: 0.9968 - val_loss: 0.2031 - val_accuracy: 0.9713\n","Epoch 382/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0155 - accuracy: 0.9974 - val_loss: 0.2188 - val_accuracy: 0.9718\n","Epoch 383/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0148 - accuracy: 0.9977 - val_loss: 0.2177 - val_accuracy: 0.9713\n","Epoch 384/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0152 - accuracy: 0.9972 - val_loss: 0.2162 - val_accuracy: 0.9707\n","Epoch 385/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0146 - accuracy: 0.9970 - val_loss: 0.2182 - val_accuracy: 0.9718\n","Epoch 386/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0156 - accuracy: 0.9967 - val_loss: 0.2182 - val_accuracy: 0.9717\n","Epoch 387/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0149 - accuracy: 0.9977 - val_loss: 0.2113 - val_accuracy: 0.9709\n","Epoch 388/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0134 - accuracy: 0.9978 - val_loss: 0.2175 - val_accuracy: 0.9711\n","Epoch 389/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0152 - accuracy: 0.9974 - val_loss: 0.2187 - val_accuracy: 0.9718\n","Epoch 390/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0174 - accuracy: 0.9966 - val_loss: 0.2264 - val_accuracy: 0.9722\n","Epoch 391/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.2136 - val_accuracy: 0.9707\n","Epoch 392/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0147 - accuracy: 0.9970 - val_loss: 0.2314 - val_accuracy: 0.9722\n","Epoch 393/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.2329 - val_accuracy: 0.9720\n","Epoch 394/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0140 - accuracy: 0.9979 - val_loss: 0.2343 - val_accuracy: 0.9722\n","Epoch 395/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0154 - accuracy: 0.9972 - val_loss: 0.2244 - val_accuracy: 0.9713\n","Epoch 396/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9979 - val_loss: 0.2115 - val_accuracy: 0.9711\n","Epoch 397/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0140 - accuracy: 0.9976 - val_loss: 0.2132 - val_accuracy: 0.9718\n","Epoch 398/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0131 - accuracy: 0.9977 - val_loss: 0.2132 - val_accuracy: 0.9713\n","Epoch 399/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0154 - accuracy: 0.9974 - val_loss: 0.2245 - val_accuracy: 0.9705\n","Epoch 400/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0141 - accuracy: 0.9977 - val_loss: 0.2179 - val_accuracy: 0.9711\n","Epoch 401/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.2242 - val_accuracy: 0.9713\n","Epoch 402/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0157 - accuracy: 0.9970 - val_loss: 0.2222 - val_accuracy: 0.9711\n","Epoch 403/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0141 - accuracy: 0.9976 - val_loss: 0.2328 - val_accuracy: 0.9718\n","Epoch 404/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.2209 - val_accuracy: 0.9717\n","Epoch 405/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.2090 - val_accuracy: 0.9709\n","Epoch 406/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0156 - accuracy: 0.9975 - val_loss: 0.2176 - val_accuracy: 0.9717\n","Epoch 407/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.2107 - val_accuracy: 0.9705\n","Epoch 408/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0140 - accuracy: 0.9974 - val_loss: 0.2241 - val_accuracy: 0.9717\n","Epoch 409/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9973 - val_loss: 0.2256 - val_accuracy: 0.9717\n","Epoch 410/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9978 - val_loss: 0.2261 - val_accuracy: 0.9713\n","Epoch 411/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.2164 - val_accuracy: 0.9709\n","Epoch 412/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0133 - accuracy: 0.9980 - val_loss: 0.2202 - val_accuracy: 0.9711\n","Epoch 413/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9978 - val_loss: 0.2354 - val_accuracy: 0.9718\n","Epoch 414/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.2270 - val_accuracy: 0.9715\n","Epoch 415/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.2185 - val_accuracy: 0.9704\n","Epoch 416/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.2235 - val_accuracy: 0.9715\n","Epoch 417/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0125 - accuracy: 0.9977 - val_loss: 0.2109 - val_accuracy: 0.9700\n","Epoch 418/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0144 - accuracy: 0.9971 - val_loss: 0.2261 - val_accuracy: 0.9707\n","Epoch 419/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0140 - accuracy: 0.9977 - val_loss: 0.2239 - val_accuracy: 0.9717\n","Epoch 420/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.2316 - val_accuracy: 0.9717\n","Epoch 421/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.2131 - val_accuracy: 0.9702\n","Epoch 422/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0139 - accuracy: 0.9978 - val_loss: 0.2193 - val_accuracy: 0.9715\n","Epoch 423/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0140 - accuracy: 0.9978 - val_loss: 0.2273 - val_accuracy: 0.9707\n","Epoch 424/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9986 - val_loss: 0.2408 - val_accuracy: 0.9717\n","Epoch 425/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.2235 - val_accuracy: 0.9713\n","Epoch 426/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0148 - accuracy: 0.9975 - val_loss: 0.2148 - val_accuracy: 0.9709\n","Epoch 427/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 0.2224 - val_accuracy: 0.9707\n","Epoch 428/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0135 - accuracy: 0.9980 - val_loss: 0.2029 - val_accuracy: 0.9676\n","Epoch 429/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9980 - val_loss: 0.2286 - val_accuracy: 0.9709\n","Epoch 430/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9982 - val_loss: 0.2323 - val_accuracy: 0.9709\n","Epoch 431/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0148 - accuracy: 0.9975 - val_loss: 0.2292 - val_accuracy: 0.9715\n","Epoch 432/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0140 - accuracy: 0.9979 - val_loss: 0.2061 - val_accuracy: 0.9687\n","Epoch 433/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9977 - val_loss: 0.2192 - val_accuracy: 0.9707\n","Epoch 434/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0145 - accuracy: 0.9975 - val_loss: 0.2137 - val_accuracy: 0.9698\n","Epoch 435/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 0.2296 - val_accuracy: 0.9717\n","Epoch 436/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0114 - accuracy: 0.9988 - val_loss: 0.2294 - val_accuracy: 0.9715\n","Epoch 437/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0140 - accuracy: 0.9978 - val_loss: 0.2221 - val_accuracy: 0.9713\n","Epoch 438/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0149 - accuracy: 0.9972 - val_loss: 0.2171 - val_accuracy: 0.9705\n","Epoch 439/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0141 - accuracy: 0.9971 - val_loss: 0.2198 - val_accuracy: 0.9709\n","Epoch 440/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0135 - accuracy: 0.9978 - val_loss: 0.2260 - val_accuracy: 0.9705\n","Epoch 441/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0144 - accuracy: 0.9977 - val_loss: 0.2154 - val_accuracy: 0.9702\n","Epoch 442/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0142 - accuracy: 0.9975 - val_loss: 0.2232 - val_accuracy: 0.9711\n","Epoch 443/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0141 - accuracy: 0.9973 - val_loss: 0.2093 - val_accuracy: 0.9694\n","Epoch 444/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0150 - accuracy: 0.9974 - val_loss: 0.2109 - val_accuracy: 0.9707\n","Epoch 445/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0145 - accuracy: 0.9977 - val_loss: 0.2273 - val_accuracy: 0.9715\n","Epoch 446/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0163 - accuracy: 0.9966 - val_loss: 0.2090 - val_accuracy: 0.9702\n","Epoch 447/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0148 - accuracy: 0.9971 - val_loss: 0.2128 - val_accuracy: 0.9694\n","Epoch 448/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9979 - val_loss: 0.2314 - val_accuracy: 0.9707\n","Epoch 449/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.2172 - val_accuracy: 0.9698\n","Epoch 450/1500\n","42/42 [==============================] - 1s 30ms/step - loss: 0.0144 - accuracy: 0.9974 - val_loss: 0.2186 - val_accuracy: 0.9705\n","Epoch 451/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0143 - accuracy: 0.9974 - val_loss: 0.2343 - val_accuracy: 0.9707\n","Epoch 452/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9980 - val_loss: 0.2190 - val_accuracy: 0.9694\n","Epoch 453/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0130 - accuracy: 0.9979 - val_loss: 0.2229 - val_accuracy: 0.9698\n","Epoch 454/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9976 - val_loss: 0.2196 - val_accuracy: 0.9698\n","Epoch 455/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0146 - accuracy: 0.9976 - val_loss: 0.2301 - val_accuracy: 0.9707\n","Epoch 456/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.2156 - val_accuracy: 0.9696\n","Epoch 457/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9978 - val_loss: 0.2300 - val_accuracy: 0.9704\n","Epoch 458/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0149 - accuracy: 0.9973 - val_loss: 0.2302 - val_accuracy: 0.9709\n","Epoch 459/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 0.9983 - val_loss: 0.2182 - val_accuracy: 0.9698\n","Epoch 460/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.2202 - val_accuracy: 0.9700\n","Epoch 461/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.2252 - val_accuracy: 0.9700\n","Epoch 462/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0157 - accuracy: 0.9972 - val_loss: 0.2206 - val_accuracy: 0.9692\n","Epoch 463/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.2283 - val_accuracy: 0.9700\n","Epoch 464/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0158 - accuracy: 0.9966 - val_loss: 0.2173 - val_accuracy: 0.9692\n","Epoch 465/1500\n","42/42 [==============================] - 1s 30ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.2073 - val_accuracy: 0.9683\n","Epoch 466/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0137 - accuracy: 0.9976 - val_loss: 0.2223 - val_accuracy: 0.9700\n","Epoch 467/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0148 - accuracy: 0.9971 - val_loss: 0.2239 - val_accuracy: 0.9709\n","Epoch 468/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.2330 - val_accuracy: 0.9709\n","Epoch 469/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0134 - accuracy: 0.9977 - val_loss: 0.2270 - val_accuracy: 0.9707\n","Epoch 470/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.2218 - val_accuracy: 0.9704\n","Epoch 471/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0154 - accuracy: 0.9965 - val_loss: 0.2170 - val_accuracy: 0.9702\n","Epoch 472/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.2108 - val_accuracy: 0.9705\n","Epoch 473/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9977 - val_loss: 0.2183 - val_accuracy: 0.9713\n","Epoch 474/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.2164 - val_accuracy: 0.9707\n","Epoch 475/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0163 - accuracy: 0.9965 - val_loss: 0.2148 - val_accuracy: 0.9705\n","Epoch 476/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0128 - accuracy: 0.9980 - val_loss: 0.2301 - val_accuracy: 0.9713\n","Epoch 477/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0140 - accuracy: 0.9971 - val_loss: 0.2123 - val_accuracy: 0.9705\n","Epoch 478/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.2166 - val_accuracy: 0.9700\n","Epoch 479/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9980 - val_loss: 0.2126 - val_accuracy: 0.9698\n","Epoch 480/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.2275 - val_accuracy: 0.9704\n","Epoch 481/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9977 - val_loss: 0.2327 - val_accuracy: 0.9709\n","Epoch 482/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0146 - accuracy: 0.9968 - val_loss: 0.2220 - val_accuracy: 0.9705\n","Epoch 483/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0136 - accuracy: 0.9976 - val_loss: 0.2061 - val_accuracy: 0.9694\n","Epoch 484/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.2314 - val_accuracy: 0.9707\n","Epoch 485/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.2098 - val_accuracy: 0.9711\n","Epoch 486/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0125 - accuracy: 0.9981 - val_loss: 0.2324 - val_accuracy: 0.9713\n","Epoch 487/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0124 - accuracy: 0.9983 - val_loss: 0.2056 - val_accuracy: 0.9692\n","Epoch 488/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0134 - accuracy: 0.9975 - val_loss: 0.2443 - val_accuracy: 0.9711\n","Epoch 489/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9978 - val_loss: 0.2243 - val_accuracy: 0.9713\n","Epoch 490/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0141 - accuracy: 0.9976 - val_loss: 0.2251 - val_accuracy: 0.9715\n","Epoch 491/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0153 - accuracy: 0.9976 - val_loss: 0.2345 - val_accuracy: 0.9713\n","Epoch 492/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0157 - accuracy: 0.9968 - val_loss: 0.2215 - val_accuracy: 0.9709\n","Epoch 493/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0140 - accuracy: 0.9974 - val_loss: 0.2127 - val_accuracy: 0.9705\n","Epoch 494/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0143 - accuracy: 0.9970 - val_loss: 0.2124 - val_accuracy: 0.9700\n","Epoch 495/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 0.2192 - val_accuracy: 0.9700\n","Epoch 496/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 0.2087 - val_accuracy: 0.9691\n","Epoch 497/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0146 - accuracy: 0.9970 - val_loss: 0.2215 - val_accuracy: 0.9692\n","Epoch 498/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0143 - accuracy: 0.9974 - val_loss: 0.2307 - val_accuracy: 0.9707\n","Epoch 499/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0148 - accuracy: 0.9967 - val_loss: 0.2109 - val_accuracy: 0.9696\n","Epoch 500/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.2339 - val_accuracy: 0.9711\n","Epoch 501/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0146 - accuracy: 0.9971 - val_loss: 0.2078 - val_accuracy: 0.9696\n","Epoch 502/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0118 - accuracy: 0.9986 - val_loss: 0.2244 - val_accuracy: 0.9717\n","Epoch 503/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: 0.2211 - val_accuracy: 0.9709\n","Epoch 504/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.2132 - val_accuracy: 0.9702\n","Epoch 505/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0158 - accuracy: 0.9971 - val_loss: 0.2211 - val_accuracy: 0.9711\n","Epoch 506/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.2117 - val_accuracy: 0.9711\n","Epoch 507/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0121 - accuracy: 0.9983 - val_loss: 0.2190 - val_accuracy: 0.9718\n","Epoch 508/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0136 - accuracy: 0.9979 - val_loss: 0.2243 - val_accuracy: 0.9717\n","Epoch 509/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0149 - accuracy: 0.9971 - val_loss: 0.2183 - val_accuracy: 0.9720\n","Epoch 510/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 0.2195 - val_accuracy: 0.9717\n","Epoch 511/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.2221 - val_accuracy: 0.9707\n","Epoch 512/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0141 - accuracy: 0.9973 - val_loss: 0.2195 - val_accuracy: 0.9711\n","Epoch 513/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0134 - accuracy: 0.9976 - val_loss: 0.2094 - val_accuracy: 0.9704\n","Epoch 514/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 0.2259 - val_accuracy: 0.9718\n","Epoch 515/1500\n","42/42 [==============================] - 1s 30ms/step - loss: 0.0133 - accuracy: 0.9975 - val_loss: 0.2281 - val_accuracy: 0.9717\n","Epoch 516/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9981 - val_loss: 0.2233 - val_accuracy: 0.9709\n","Epoch 517/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0149 - accuracy: 0.9971 - val_loss: 0.2377 - val_accuracy: 0.9726\n","Epoch 518/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0154 - accuracy: 0.9968 - val_loss: 0.2102 - val_accuracy: 0.9689\n","Epoch 519/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 0.2445 - val_accuracy: 0.9718\n","Epoch 520/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0159 - accuracy: 0.9963 - val_loss: 0.2354 - val_accuracy: 0.9717\n","Epoch 521/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0135 - accuracy: 0.9979 - val_loss: 0.2312 - val_accuracy: 0.9711\n","Epoch 522/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9974 - val_loss: 0.2292 - val_accuracy: 0.9707\n","Epoch 523/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.2231 - val_accuracy: 0.9700\n","Epoch 524/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9980 - val_loss: 0.2216 - val_accuracy: 0.9702\n","Epoch 525/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0139 - accuracy: 0.9979 - val_loss: 0.2391 - val_accuracy: 0.9713\n","Epoch 526/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0134 - accuracy: 0.9971 - val_loss: 0.2136 - val_accuracy: 0.9702\n","Epoch 527/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0144 - accuracy: 0.9975 - val_loss: 0.2368 - val_accuracy: 0.9711\n","Epoch 528/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0136 - accuracy: 0.9972 - val_loss: 0.2202 - val_accuracy: 0.9704\n","Epoch 529/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9982 - val_loss: 0.2255 - val_accuracy: 0.9704\n","Epoch 530/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.2246 - val_accuracy: 0.9702\n","Epoch 531/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0128 - accuracy: 0.9981 - val_loss: 0.2351 - val_accuracy: 0.9702\n","Epoch 532/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0136 - accuracy: 0.9974 - val_loss: 0.2215 - val_accuracy: 0.9696\n","Epoch 533/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0152 - accuracy: 0.9977 - val_loss: 0.2364 - val_accuracy: 0.9702\n","Epoch 534/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0162 - accuracy: 0.9968 - val_loss: 0.2324 - val_accuracy: 0.9698\n","Epoch 535/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 0.2202 - val_accuracy: 0.9685\n","Epoch 536/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0149 - accuracy: 0.9976 - val_loss: 0.2320 - val_accuracy: 0.9702\n","Epoch 537/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0140 - accuracy: 0.9972 - val_loss: 0.2362 - val_accuracy: 0.9711\n","Epoch 538/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0153 - accuracy: 0.9968 - val_loss: 0.2188 - val_accuracy: 0.9696\n","Epoch 539/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0143 - accuracy: 0.9975 - val_loss: 0.2255 - val_accuracy: 0.9698\n","Epoch 540/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0134 - accuracy: 0.9973 - val_loss: 0.2281 - val_accuracy: 0.9705\n","Epoch 541/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0140 - accuracy: 0.9973 - val_loss: 0.2268 - val_accuracy: 0.9705\n","Epoch 542/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0145 - accuracy: 0.9977 - val_loss: 0.2228 - val_accuracy: 0.9700\n","Epoch 543/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0154 - accuracy: 0.9974 - val_loss: 0.2251 - val_accuracy: 0.9717\n","Epoch 544/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9988 - val_loss: 0.2312 - val_accuracy: 0.9728\n","Epoch 545/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0123 - accuracy: 0.9982 - val_loss: 0.2261 - val_accuracy: 0.9717\n","Epoch 546/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0124 - accuracy: 0.9983 - val_loss: 0.2463 - val_accuracy: 0.9718\n","Epoch 547/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.2577 - val_accuracy: 0.9722\n","Epoch 548/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0142 - accuracy: 0.9979 - val_loss: 0.2267 - val_accuracy: 0.9707\n","Epoch 549/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0143 - accuracy: 0.9976 - val_loss: 0.2255 - val_accuracy: 0.9700\n","Epoch 550/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9978 - val_loss: 0.2212 - val_accuracy: 0.9705\n","Epoch 551/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0135 - accuracy: 0.9971 - val_loss: 0.2378 - val_accuracy: 0.9707\n","Epoch 552/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.2333 - val_accuracy: 0.9705\n","Epoch 553/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0119 - accuracy: 0.9979 - val_loss: 0.2288 - val_accuracy: 0.9704\n","Epoch 554/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0143 - accuracy: 0.9975 - val_loss: 0.2382 - val_accuracy: 0.9707\n","Epoch 555/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0122 - accuracy: 0.9981 - val_loss: 0.2173 - val_accuracy: 0.9709\n","Epoch 556/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 0.2343 - val_accuracy: 0.9707\n","Epoch 557/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 0.2376 - val_accuracy: 0.9717\n","Epoch 558/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.2176 - val_accuracy: 0.9698\n","Epoch 559/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 0.2388 - val_accuracy: 0.9711\n","Epoch 560/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0158 - accuracy: 0.9967 - val_loss: 0.2352 - val_accuracy: 0.9713\n","Epoch 561/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9971 - val_loss: 0.2305 - val_accuracy: 0.9704\n","Epoch 562/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0117 - accuracy: 0.9981 - val_loss: 0.2286 - val_accuracy: 0.9705\n","Epoch 563/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.2174 - val_accuracy: 0.9694\n","Epoch 564/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: 0.2352 - val_accuracy: 0.9702\n","Epoch 565/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0128 - accuracy: 0.9981 - val_loss: 0.2257 - val_accuracy: 0.9694\n","Epoch 566/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9985 - val_loss: 0.2346 - val_accuracy: 0.9704\n","Epoch 567/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.2308 - val_accuracy: 0.9709\n","Epoch 568/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9973 - val_loss: 0.2213 - val_accuracy: 0.9694\n","Epoch 569/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0147 - accuracy: 0.9970 - val_loss: 0.2314 - val_accuracy: 0.9705\n","Epoch 570/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0122 - accuracy: 0.9980 - val_loss: 0.2279 - val_accuracy: 0.9709\n","Epoch 571/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0136 - accuracy: 0.9979 - val_loss: 0.2250 - val_accuracy: 0.9705\n","Epoch 572/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9983 - val_loss: 0.2234 - val_accuracy: 0.9707\n","Epoch 573/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9977 - val_loss: 0.2219 - val_accuracy: 0.9705\n","Epoch 574/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0124 - accuracy: 0.9982 - val_loss: 0.2162 - val_accuracy: 0.9692\n","Epoch 575/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0145 - accuracy: 0.9976 - val_loss: 0.2314 - val_accuracy: 0.9704\n","Epoch 576/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0133 - accuracy: 0.9978 - val_loss: 0.2394 - val_accuracy: 0.9704\n","Epoch 577/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.2258 - val_accuracy: 0.9700\n","Epoch 578/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0134 - accuracy: 0.9978 - val_loss: 0.2173 - val_accuracy: 0.9694\n","Epoch 579/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0136 - accuracy: 0.9975 - val_loss: 0.2286 - val_accuracy: 0.9704\n","Epoch 580/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0122 - accuracy: 0.9982 - val_loss: 0.2193 - val_accuracy: 0.9700\n","Epoch 581/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0139 - accuracy: 0.9980 - val_loss: 0.2276 - val_accuracy: 0.9707\n","Epoch 582/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0131 - accuracy: 0.9980 - val_loss: 0.2233 - val_accuracy: 0.9705\n","Epoch 583/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0137 - accuracy: 0.9979 - val_loss: 0.2233 - val_accuracy: 0.9696\n","Epoch 584/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0144 - accuracy: 0.9972 - val_loss: 0.2100 - val_accuracy: 0.9685\n","Epoch 585/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0142 - accuracy: 0.9975 - val_loss: 0.2152 - val_accuracy: 0.9696\n","Epoch 586/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0123 - accuracy: 0.9982 - val_loss: 0.2152 - val_accuracy: 0.9698\n","Epoch 587/1500\n","42/42 [==============================] - 1s 34ms/step - loss: 0.0146 - accuracy: 0.9974 - val_loss: 0.2173 - val_accuracy: 0.9709\n","Epoch 588/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.2287 - val_accuracy: 0.9718\n","Epoch 589/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0126 - accuracy: 0.9978 - val_loss: 0.2052 - val_accuracy: 0.9698\n","Epoch 590/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0143 - accuracy: 0.9978 - val_loss: 0.2435 - val_accuracy: 0.9715\n","Epoch 591/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0141 - accuracy: 0.9976 - val_loss: 0.2227 - val_accuracy: 0.9709\n","Epoch 592/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0156 - accuracy: 0.9967 - val_loss: 0.2320 - val_accuracy: 0.9713\n","Epoch 593/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.2230 - val_accuracy: 0.9704\n","Epoch 594/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0151 - accuracy: 0.9974 - val_loss: 0.2173 - val_accuracy: 0.9711\n","Epoch 595/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 0.2163 - val_accuracy: 0.9707\n","Epoch 596/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0138 - accuracy: 0.9977 - val_loss: 0.2043 - val_accuracy: 0.9687\n","Epoch 597/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0137 - accuracy: 0.9978 - val_loss: 0.2135 - val_accuracy: 0.9696\n","Epoch 598/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0141 - accuracy: 0.9972 - val_loss: 0.2350 - val_accuracy: 0.9700\n","Epoch 599/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0149 - accuracy: 0.9972 - val_loss: 0.2204 - val_accuracy: 0.9705\n","Epoch 600/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0149 - accuracy: 0.9974 - val_loss: 0.2205 - val_accuracy: 0.9702\n","Epoch 601/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0143 - accuracy: 0.9968 - val_loss: 0.2401 - val_accuracy: 0.9702\n","Epoch 602/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0135 - accuracy: 0.9976 - val_loss: 0.2402 - val_accuracy: 0.9700\n","Epoch 603/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9978 - val_loss: 0.2214 - val_accuracy: 0.9698\n","Epoch 604/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.2174 - val_accuracy: 0.9702\n","Epoch 605/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0137 - accuracy: 0.9978 - val_loss: 0.2226 - val_accuracy: 0.9705\n","Epoch 606/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.2244 - val_accuracy: 0.9709\n","Epoch 607/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0139 - accuracy: 0.9979 - val_loss: 0.2360 - val_accuracy: 0.9707\n","Epoch 608/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0145 - accuracy: 0.9971 - val_loss: 0.2188 - val_accuracy: 0.9707\n","Epoch 609/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0134 - accuracy: 0.9979 - val_loss: 0.2249 - val_accuracy: 0.9700\n","Epoch 610/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0149 - accuracy: 0.9972 - val_loss: 0.2187 - val_accuracy: 0.9694\n","Epoch 611/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0162 - accuracy: 0.9964 - val_loss: 0.2242 - val_accuracy: 0.9702\n","Epoch 612/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0150 - accuracy: 0.9971 - val_loss: 0.2261 - val_accuracy: 0.9702\n","Epoch 613/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0143 - accuracy: 0.9977 - val_loss: 0.2443 - val_accuracy: 0.9702\n","Epoch 614/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0158 - accuracy: 0.9968 - val_loss: 0.2236 - val_accuracy: 0.9700\n","Epoch 615/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0152 - accuracy: 0.9979 - val_loss: 0.2251 - val_accuracy: 0.9709\n","Epoch 616/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0119 - accuracy: 0.9987 - val_loss: 0.2346 - val_accuracy: 0.9704\n","Epoch 617/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0133 - accuracy: 0.9979 - val_loss: 0.2295 - val_accuracy: 0.9713\n","Epoch 618/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.2131 - val_accuracy: 0.9698\n","Epoch 619/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0119 - accuracy: 0.9979 - val_loss: 0.2263 - val_accuracy: 0.9698\n","Epoch 620/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0129 - accuracy: 0.9978 - val_loss: 0.2369 - val_accuracy: 0.9705\n","Epoch 621/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0144 - accuracy: 0.9972 - val_loss: 0.2253 - val_accuracy: 0.9713\n","Epoch 622/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0153 - accuracy: 0.9971 - val_loss: 0.2110 - val_accuracy: 0.9702\n","Epoch 623/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.2449 - val_accuracy: 0.9711\n","Epoch 624/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0155 - accuracy: 0.9973 - val_loss: 0.2234 - val_accuracy: 0.9707\n","Epoch 625/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0130 - accuracy: 0.9980 - val_loss: 0.2203 - val_accuracy: 0.9711\n","Epoch 626/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0156 - accuracy: 0.9968 - val_loss: 0.2359 - val_accuracy: 0.9702\n","Epoch 627/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0145 - accuracy: 0.9973 - val_loss: 0.2266 - val_accuracy: 0.9709\n","Epoch 628/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0164 - accuracy: 0.9966 - val_loss: 0.2197 - val_accuracy: 0.9700\n","Epoch 629/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0149 - accuracy: 0.9971 - val_loss: 0.2206 - val_accuracy: 0.9715\n","Epoch 630/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0118 - accuracy: 0.9982 - val_loss: 0.2288 - val_accuracy: 0.9711\n","Epoch 631/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0114 - accuracy: 0.9989 - val_loss: 0.2255 - val_accuracy: 0.9713\n","Epoch 632/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0136 - accuracy: 0.9979 - val_loss: 0.2178 - val_accuracy: 0.9709\n","Epoch 633/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0134 - accuracy: 0.9976 - val_loss: 0.2409 - val_accuracy: 0.9715\n","Epoch 634/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 0.2105 - val_accuracy: 0.9700\n","Epoch 635/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0111 - accuracy: 0.9987 - val_loss: 0.2299 - val_accuracy: 0.9709\n","Epoch 636/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.2220 - val_accuracy: 0.9700\n","Epoch 637/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.2202 - val_accuracy: 0.9702\n","Epoch 638/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.2169 - val_accuracy: 0.9700\n","Epoch 639/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0115 - accuracy: 0.9984 - val_loss: 0.2185 - val_accuracy: 0.9698\n","Epoch 640/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9977 - val_loss: 0.2239 - val_accuracy: 0.9707\n","Epoch 641/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9977 - val_loss: 0.2239 - val_accuracy: 0.9705\n","Epoch 642/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0126 - accuracy: 0.9976 - val_loss: 0.2379 - val_accuracy: 0.9709\n","Epoch 643/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0129 - accuracy: 0.9976 - val_loss: 0.2159 - val_accuracy: 0.9704\n","Epoch 644/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0121 - accuracy: 0.9978 - val_loss: 0.2268 - val_accuracy: 0.9709\n","Epoch 645/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 0.2237 - val_accuracy: 0.9707\n","Epoch 646/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 0.2138 - val_accuracy: 0.9692\n","Epoch 647/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9978 - val_loss: 0.2267 - val_accuracy: 0.9700\n","Epoch 648/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0121 - accuracy: 0.9980 - val_loss: 0.2275 - val_accuracy: 0.9707\n","Epoch 649/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0130 - accuracy: 0.9979 - val_loss: 0.2328 - val_accuracy: 0.9713\n","Epoch 650/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 0.2174 - val_accuracy: 0.9694\n","Epoch 651/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 0.2353 - val_accuracy: 0.9709\n","Epoch 652/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0134 - accuracy: 0.9975 - val_loss: 0.2253 - val_accuracy: 0.9702\n","Epoch 653/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.2303 - val_accuracy: 0.9702\n","Epoch 654/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0115 - accuracy: 0.9984 - val_loss: 0.2249 - val_accuracy: 0.9705\n","Epoch 655/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.2210 - val_accuracy: 0.9702\n","Epoch 656/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0141 - accuracy: 0.9979 - val_loss: 0.2271 - val_accuracy: 0.9711\n","Epoch 657/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9980 - val_loss: 0.2219 - val_accuracy: 0.9698\n","Epoch 658/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9976 - val_loss: 0.2403 - val_accuracy: 0.9711\n","Epoch 659/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0135 - accuracy: 0.9974 - val_loss: 0.2156 - val_accuracy: 0.9700\n","Epoch 660/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0137 - accuracy: 0.9979 - val_loss: 0.2195 - val_accuracy: 0.9702\n","Epoch 661/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0126 - accuracy: 0.9983 - val_loss: 0.2308 - val_accuracy: 0.9715\n","Epoch 662/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 0.2227 - val_accuracy: 0.9707\n","Epoch 663/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0142 - accuracy: 0.9975 - val_loss: 0.2374 - val_accuracy: 0.9728\n","Epoch 664/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0137 - accuracy: 0.9972 - val_loss: 0.2192 - val_accuracy: 0.9704\n","Epoch 665/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0159 - accuracy: 0.9965 - val_loss: 0.2386 - val_accuracy: 0.9709\n","Epoch 666/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 0.2327 - val_accuracy: 0.9718\n","Epoch 667/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9977 - val_loss: 0.2297 - val_accuracy: 0.9713\n","Epoch 668/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0121 - accuracy: 0.9980 - val_loss: 0.2326 - val_accuracy: 0.9707\n","Epoch 669/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0129 - accuracy: 0.9982 - val_loss: 0.2230 - val_accuracy: 0.9692\n","Epoch 670/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9978 - val_loss: 0.2351 - val_accuracy: 0.9704\n","Epoch 671/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0140 - accuracy: 0.9976 - val_loss: 0.2213 - val_accuracy: 0.9696\n","Epoch 672/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9979 - val_loss: 0.2243 - val_accuracy: 0.9704\n","Epoch 673/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0145 - accuracy: 0.9972 - val_loss: 0.2268 - val_accuracy: 0.9691\n","Epoch 674/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.2285 - val_accuracy: 0.9692\n","Epoch 675/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.2297 - val_accuracy: 0.9694\n","Epoch 676/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0121 - accuracy: 0.9982 - val_loss: 0.2349 - val_accuracy: 0.9700\n","Epoch 677/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0151 - accuracy: 0.9967 - val_loss: 0.2327 - val_accuracy: 0.9696\n","Epoch 678/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9978 - val_loss: 0.2281 - val_accuracy: 0.9700\n","Epoch 679/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0140 - accuracy: 0.9977 - val_loss: 0.2400 - val_accuracy: 0.9707\n","Epoch 680/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0141 - accuracy: 0.9979 - val_loss: 0.2312 - val_accuracy: 0.9698\n","Epoch 681/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0118 - accuracy: 0.9979 - val_loss: 0.2514 - val_accuracy: 0.9711\n","Epoch 682/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.2381 - val_accuracy: 0.9702\n","Epoch 683/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0141 - accuracy: 0.9979 - val_loss: 0.2240 - val_accuracy: 0.9702\n","Epoch 684/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9977 - val_loss: 0.2214 - val_accuracy: 0.9691\n","Epoch 685/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0151 - accuracy: 0.9974 - val_loss: 0.2466 - val_accuracy: 0.9704\n","Epoch 686/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0160 - accuracy: 0.9974 - val_loss: 0.2321 - val_accuracy: 0.9705\n","Epoch 687/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0125 - accuracy: 0.9982 - val_loss: 0.2303 - val_accuracy: 0.9705\n","Epoch 688/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.2368 - val_accuracy: 0.9707\n","Epoch 689/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9980 - val_loss: 0.2318 - val_accuracy: 0.9713\n","Epoch 690/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.2333 - val_accuracy: 0.9705\n","Epoch 691/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0122 - accuracy: 0.9981 - val_loss: 0.2374 - val_accuracy: 0.9694\n","Epoch 692/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0135 - accuracy: 0.9977 - val_loss: 0.2426 - val_accuracy: 0.9705\n","Epoch 693/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9978 - val_loss: 0.2386 - val_accuracy: 0.9704\n","Epoch 694/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0115 - accuracy: 0.9985 - val_loss: 0.2380 - val_accuracy: 0.9702\n","Epoch 695/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.2365 - val_accuracy: 0.9696\n","Epoch 696/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9978 - val_loss: 0.2203 - val_accuracy: 0.9694\n","Epoch 697/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.2196 - val_accuracy: 0.9694\n","Epoch 698/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0140 - accuracy: 0.9974 - val_loss: 0.2314 - val_accuracy: 0.9715\n","Epoch 699/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9979 - val_loss: 0.2239 - val_accuracy: 0.9707\n","Epoch 700/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9978 - val_loss: 0.2229 - val_accuracy: 0.9702\n","Epoch 701/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 0.9984 - val_loss: 0.2264 - val_accuracy: 0.9707\n","Epoch 702/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0144 - accuracy: 0.9970 - val_loss: 0.2402 - val_accuracy: 0.9707\n","Epoch 703/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 0.2207 - val_accuracy: 0.9694\n","Epoch 704/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0126 - accuracy: 0.9982 - val_loss: 0.2469 - val_accuracy: 0.9713\n","Epoch 705/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9973 - val_loss: 0.2445 - val_accuracy: 0.9707\n","Epoch 706/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0124 - accuracy: 0.9986 - val_loss: 0.2383 - val_accuracy: 0.9705\n","Epoch 707/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0148 - accuracy: 0.9971 - val_loss: 0.2230 - val_accuracy: 0.9694\n","Epoch 708/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 0.2366 - val_accuracy: 0.9704\n","Epoch 709/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9978 - val_loss: 0.2508 - val_accuracy: 0.9717\n","Epoch 710/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0139 - accuracy: 0.9977 - val_loss: 0.2285 - val_accuracy: 0.9698\n","Epoch 711/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0117 - accuracy: 0.9981 - val_loss: 0.2319 - val_accuracy: 0.9692\n","Epoch 712/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0149 - accuracy: 0.9971 - val_loss: 0.2391 - val_accuracy: 0.9681\n","Epoch 713/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.2311 - val_accuracy: 0.9698\n","Epoch 714/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.2331 - val_accuracy: 0.9700\n","Epoch 715/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0145 - accuracy: 0.9975 - val_loss: 0.2299 - val_accuracy: 0.9707\n","Epoch 716/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9976 - val_loss: 0.2203 - val_accuracy: 0.9691\n","Epoch 717/1500\n","42/42 [==============================] - 2s 39ms/step - loss: 0.0149 - accuracy: 0.9974 - val_loss: 0.2427 - val_accuracy: 0.9702\n","Epoch 718/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9976 - val_loss: 0.2417 - val_accuracy: 0.9705\n","Epoch 719/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0136 - accuracy: 0.9978 - val_loss: 0.2309 - val_accuracy: 0.9698\n","Epoch 720/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.2394 - val_accuracy: 0.9704\n","Epoch 721/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.2336 - val_accuracy: 0.9700\n","Epoch 722/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9977 - val_loss: 0.2445 - val_accuracy: 0.9698\n","Epoch 723/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0125 - accuracy: 0.9981 - val_loss: 0.2253 - val_accuracy: 0.9696\n","Epoch 724/1500\n","42/42 [==============================] - 1s 30ms/step - loss: 0.0137 - accuracy: 0.9977 - val_loss: 0.2293 - val_accuracy: 0.9694\n","Epoch 725/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9973 - val_loss: 0.2208 - val_accuracy: 0.9696\n","Epoch 726/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.2341 - val_accuracy: 0.9700\n","Epoch 727/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0121 - accuracy: 0.9979 - val_loss: 0.2551 - val_accuracy: 0.9702\n","Epoch 728/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.2841 - val_accuracy: 0.9709\n","Epoch 729/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0145 - accuracy: 0.9973 - val_loss: 0.2394 - val_accuracy: 0.9698\n","Epoch 730/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0128 - accuracy: 0.9985 - val_loss: 0.2238 - val_accuracy: 0.9694\n","Epoch 731/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0115 - accuracy: 0.9980 - val_loss: 0.2287 - val_accuracy: 0.9705\n","Epoch 732/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0149 - accuracy: 0.9974 - val_loss: 0.2211 - val_accuracy: 0.9694\n","Epoch 733/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 0.9978 - val_loss: 0.2432 - val_accuracy: 0.9705\n","Epoch 734/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0125 - accuracy: 0.9981 - val_loss: 0.2434 - val_accuracy: 0.9704\n","Epoch 735/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0121 - accuracy: 0.9981 - val_loss: 0.2166 - val_accuracy: 0.9691\n","Epoch 736/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0119 - accuracy: 0.9980 - val_loss: 0.2462 - val_accuracy: 0.9717\n","Epoch 737/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.2239 - val_accuracy: 0.9704\n","Epoch 738/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 0.2257 - val_accuracy: 0.9696\n","Epoch 739/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0123 - accuracy: 0.9981 - val_loss: 0.2278 - val_accuracy: 0.9705\n","Epoch 740/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.2489 - val_accuracy: 0.9705\n","Epoch 741/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0124 - accuracy: 0.9977 - val_loss: 0.2386 - val_accuracy: 0.9707\n","Epoch 742/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0125 - accuracy: 0.9982 - val_loss: 0.2509 - val_accuracy: 0.9713\n","Epoch 743/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0122 - accuracy: 0.9981 - val_loss: 0.2425 - val_accuracy: 0.9713\n","Epoch 744/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0132 - accuracy: 0.9977 - val_loss: 0.2363 - val_accuracy: 0.9711\n","Epoch 745/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 0.2286 - val_accuracy: 0.9715\n","Epoch 746/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0128 - accuracy: 0.9977 - val_loss: 0.2363 - val_accuracy: 0.9717\n","Epoch 747/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0123 - accuracy: 0.9979 - val_loss: 0.2228 - val_accuracy: 0.9707\n","Epoch 748/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0119 - accuracy: 0.9983 - val_loss: 0.2357 - val_accuracy: 0.9715\n","Epoch 749/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 0.2444 - val_accuracy: 0.9717\n","Epoch 750/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.2242 - val_accuracy: 0.9713\n","Epoch 751/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0106 - accuracy: 0.9988 - val_loss: 0.2296 - val_accuracy: 0.9711\n","Epoch 752/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.2383 - val_accuracy: 0.9704\n","Epoch 753/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0126 - accuracy: 0.9984 - val_loss: 0.2251 - val_accuracy: 0.9705\n","Epoch 754/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0125 - accuracy: 0.9973 - val_loss: 0.2456 - val_accuracy: 0.9713\n","Epoch 755/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0154 - accuracy: 0.9967 - val_loss: 0.2173 - val_accuracy: 0.9689\n","Epoch 756/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0146 - accuracy: 0.9976 - val_loss: 0.2338 - val_accuracy: 0.9702\n","Epoch 757/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 0.2421 - val_accuracy: 0.9715\n","Epoch 758/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.2284 - val_accuracy: 0.9700\n","Epoch 759/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0127 - accuracy: 0.9976 - val_loss: 0.2331 - val_accuracy: 0.9711\n","Epoch 760/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0129 - accuracy: 0.9977 - val_loss: 0.2318 - val_accuracy: 0.9707\n","Epoch 761/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0147 - accuracy: 0.9973 - val_loss: 0.2123 - val_accuracy: 0.9694\n","Epoch 762/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.2507 - val_accuracy: 0.9702\n","Epoch 763/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0128 - accuracy: 0.9983 - val_loss: 0.2329 - val_accuracy: 0.9704\n","Epoch 764/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9974 - val_loss: 0.2251 - val_accuracy: 0.9698\n","Epoch 765/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0145 - accuracy: 0.9972 - val_loss: 0.2183 - val_accuracy: 0.9711\n","Epoch 766/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.2211 - val_accuracy: 0.9715\n","Epoch 767/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 0.2399 - val_accuracy: 0.9707\n","Epoch 768/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0128 - accuracy: 0.9977 - val_loss: 0.2254 - val_accuracy: 0.9707\n","Epoch 769/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0143 - accuracy: 0.9970 - val_loss: 0.2364 - val_accuracy: 0.9709\n","Epoch 770/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0121 - accuracy: 0.9978 - val_loss: 0.2344 - val_accuracy: 0.9715\n","Epoch 771/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.2415 - val_accuracy: 0.9715\n","Epoch 772/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0139 - accuracy: 0.9979 - val_loss: 0.2302 - val_accuracy: 0.9709\n","Epoch 773/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0121 - accuracy: 0.9985 - val_loss: 0.2264 - val_accuracy: 0.9700\n","Epoch 774/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.2353 - val_accuracy: 0.9704\n","Epoch 775/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0130 - accuracy: 0.9982 - val_loss: 0.2424 - val_accuracy: 0.9709\n","Epoch 776/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0156 - accuracy: 0.9971 - val_loss: 0.2160 - val_accuracy: 0.9696\n","Epoch 777/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.2361 - val_accuracy: 0.9700\n","Epoch 778/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0150 - accuracy: 0.9973 - val_loss: 0.2248 - val_accuracy: 0.9696\n","Epoch 779/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9982 - val_loss: 0.2338 - val_accuracy: 0.9704\n","Epoch 780/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 0.2313 - val_accuracy: 0.9705\n","Epoch 781/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0137 - accuracy: 0.9978 - val_loss: 0.2290 - val_accuracy: 0.9709\n","Epoch 782/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0119 - accuracy: 0.9979 - val_loss: 0.2347 - val_accuracy: 0.9711\n","Epoch 783/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0144 - accuracy: 0.9972 - val_loss: 0.2386 - val_accuracy: 0.9707\n","Epoch 784/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9978 - val_loss: 0.2605 - val_accuracy: 0.9709\n","Epoch 785/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0123 - accuracy: 0.9979 - val_loss: 0.2210 - val_accuracy: 0.9700\n","Epoch 786/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 0.2284 - val_accuracy: 0.9702\n","Epoch 787/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0122 - accuracy: 0.9981 - val_loss: 0.2297 - val_accuracy: 0.9709\n","Epoch 788/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0136 - accuracy: 0.9975 - val_loss: 0.2319 - val_accuracy: 0.9704\n","Epoch 789/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0143 - accuracy: 0.9975 - val_loss: 0.2408 - val_accuracy: 0.9696\n","Epoch 790/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0121 - accuracy: 0.9983 - val_loss: 0.2534 - val_accuracy: 0.9705\n","Epoch 791/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9980 - val_loss: 0.2273 - val_accuracy: 0.9694\n","Epoch 792/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.2421 - val_accuracy: 0.9705\n","Epoch 793/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0149 - accuracy: 0.9970 - val_loss: 0.2319 - val_accuracy: 0.9702\n","Epoch 794/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0142 - accuracy: 0.9981 - val_loss: 0.2623 - val_accuracy: 0.9709\n","Epoch 795/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0128 - accuracy: 0.9978 - val_loss: 0.2536 - val_accuracy: 0.9717\n","Epoch 796/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0140 - accuracy: 0.9979 - val_loss: 0.2344 - val_accuracy: 0.9707\n","Epoch 797/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9975 - val_loss: 0.2432 - val_accuracy: 0.9720\n","Epoch 798/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0117 - accuracy: 0.9978 - val_loss: 0.2318 - val_accuracy: 0.9702\n","Epoch 799/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0143 - accuracy: 0.9980 - val_loss: 0.2337 - val_accuracy: 0.9713\n","Epoch 800/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0110 - accuracy: 0.9988 - val_loss: 0.2436 - val_accuracy: 0.9715\n","Epoch 801/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0143 - accuracy: 0.9967 - val_loss: 0.2411 - val_accuracy: 0.9715\n","Epoch 802/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0121 - accuracy: 0.9980 - val_loss: 0.2372 - val_accuracy: 0.9718\n","Epoch 803/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0145 - accuracy: 0.9975 - val_loss: 0.2198 - val_accuracy: 0.9696\n","Epoch 804/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.2240 - val_accuracy: 0.9700\n","Epoch 805/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.2382 - val_accuracy: 0.9707\n","Epoch 806/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0120 - accuracy: 0.9983 - val_loss: 0.2257 - val_accuracy: 0.9687\n","Epoch 807/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.2290 - val_accuracy: 0.9698\n","Epoch 808/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0131 - accuracy: 0.9981 - val_loss: 0.2334 - val_accuracy: 0.9709\n","Epoch 809/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.2463 - val_accuracy: 0.9718\n","Epoch 810/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0115 - accuracy: 0.9984 - val_loss: 0.2386 - val_accuracy: 0.9717\n","Epoch 811/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9977 - val_loss: 0.2333 - val_accuracy: 0.9720\n","Epoch 812/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0136 - accuracy: 0.9975 - val_loss: 0.2301 - val_accuracy: 0.9705\n","Epoch 813/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0124 - accuracy: 0.9977 - val_loss: 0.2467 - val_accuracy: 0.9720\n","Epoch 814/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9977 - val_loss: 0.2412 - val_accuracy: 0.9720\n","Epoch 815/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.2310 - val_accuracy: 0.9709\n","Epoch 816/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9980 - val_loss: 0.2221 - val_accuracy: 0.9698\n","Epoch 817/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.2337 - val_accuracy: 0.9715\n","Epoch 818/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0143 - accuracy: 0.9975 - val_loss: 0.2744 - val_accuracy: 0.9722\n","Epoch 819/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0135 - accuracy: 0.9973 - val_loss: 0.2186 - val_accuracy: 0.9702\n","Epoch 820/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.2268 - val_accuracy: 0.9705\n","Epoch 821/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0115 - accuracy: 0.9984 - val_loss: 0.2481 - val_accuracy: 0.9718\n","Epoch 822/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0134 - accuracy: 0.9983 - val_loss: 0.2179 - val_accuracy: 0.9707\n","Epoch 823/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0112 - accuracy: 0.9986 - val_loss: 0.2283 - val_accuracy: 0.9713\n","Epoch 824/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.2230 - val_accuracy: 0.9711\n","Epoch 825/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0125 - accuracy: 0.9981 - val_loss: 0.2532 - val_accuracy: 0.9720\n","Epoch 826/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.2383 - val_accuracy: 0.9726\n","Epoch 827/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0141 - accuracy: 0.9972 - val_loss: 0.2385 - val_accuracy: 0.9718\n","Epoch 828/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0123 - accuracy: 0.9984 - val_loss: 0.2214 - val_accuracy: 0.9709\n","Epoch 829/1500\n","42/42 [==============================] - 1s 34ms/step - loss: 0.0123 - accuracy: 0.9980 - val_loss: 0.2230 - val_accuracy: 0.9709\n","Epoch 830/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0114 - accuracy: 0.9987 - val_loss: 0.2318 - val_accuracy: 0.9711\n","Epoch 831/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0103 - accuracy: 0.9988 - val_loss: 0.2493 - val_accuracy: 0.9724\n","Epoch 832/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0126 - accuracy: 0.9982 - val_loss: 0.2391 - val_accuracy: 0.9718\n","Epoch 833/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.2381 - val_accuracy: 0.9726\n","Epoch 834/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9975 - val_loss: 0.2345 - val_accuracy: 0.9713\n","Epoch 835/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0106 - accuracy: 0.9988 - val_loss: 0.2365 - val_accuracy: 0.9715\n","Epoch 836/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0111 - accuracy: 0.9982 - val_loss: 0.2545 - val_accuracy: 0.9720\n","Epoch 837/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 0.2307 - val_accuracy: 0.9709\n","Epoch 838/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0140 - accuracy: 0.9973 - val_loss: 0.2423 - val_accuracy: 0.9732\n","Epoch 839/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0144 - accuracy: 0.9972 - val_loss: 0.2477 - val_accuracy: 0.9715\n","Epoch 840/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.2475 - val_accuracy: 0.9711\n","Epoch 841/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9975 - val_loss: 0.2453 - val_accuracy: 0.9704\n","Epoch 842/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0147 - accuracy: 0.9973 - val_loss: 0.2391 - val_accuracy: 0.9702\n","Epoch 843/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9974 - val_loss: 0.2272 - val_accuracy: 0.9691\n","Epoch 844/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9981 - val_loss: 0.2245 - val_accuracy: 0.9689\n","Epoch 845/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0149 - accuracy: 0.9968 - val_loss: 0.2583 - val_accuracy: 0.9715\n","Epoch 846/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0145 - accuracy: 0.9964 - val_loss: 0.2377 - val_accuracy: 0.9705\n","Epoch 847/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9979 - val_loss: 0.2392 - val_accuracy: 0.9702\n","Epoch 848/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0125 - accuracy: 0.9979 - val_loss: 0.2396 - val_accuracy: 0.9717\n","Epoch 849/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0124 - accuracy: 0.9982 - val_loss: 0.2335 - val_accuracy: 0.9700\n","Epoch 850/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0122 - accuracy: 0.9977 - val_loss: 0.2340 - val_accuracy: 0.9691\n","Epoch 851/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0120 - accuracy: 0.9981 - val_loss: 0.2371 - val_accuracy: 0.9696\n","Epoch 852/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0120 - accuracy: 0.9978 - val_loss: 0.2389 - val_accuracy: 0.9702\n","Epoch 853/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0112 - accuracy: 0.9985 - val_loss: 0.2375 - val_accuracy: 0.9702\n","Epoch 854/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.2422 - val_accuracy: 0.9707\n","Epoch 855/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0118 - accuracy: 0.9984 - val_loss: 0.2383 - val_accuracy: 0.9705\n","Epoch 856/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0129 - accuracy: 0.9977 - val_loss: 0.2431 - val_accuracy: 0.9711\n","Epoch 857/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0146 - accuracy: 0.9976 - val_loss: 0.2413 - val_accuracy: 0.9707\n","Epoch 858/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9973 - val_loss: 0.2524 - val_accuracy: 0.9711\n","Epoch 859/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0144 - accuracy: 0.9973 - val_loss: 0.2338 - val_accuracy: 0.9707\n","Epoch 860/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9984 - val_loss: 0.2280 - val_accuracy: 0.9702\n","Epoch 861/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0126 - accuracy: 0.9978 - val_loss: 0.2404 - val_accuracy: 0.9715\n","Epoch 862/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 0.2332 - val_accuracy: 0.9713\n","Epoch 863/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.2482 - val_accuracy: 0.9726\n","Epoch 864/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0125 - accuracy: 0.9979 - val_loss: 0.2387 - val_accuracy: 0.9720\n","Epoch 865/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0118 - accuracy: 0.9979 - val_loss: 0.2447 - val_accuracy: 0.9717\n","Epoch 866/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9980 - val_loss: 0.2174 - val_accuracy: 0.9691\n","Epoch 867/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0117 - accuracy: 0.9984 - val_loss: 0.2382 - val_accuracy: 0.9715\n","Epoch 868/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 0.2222 - val_accuracy: 0.9698\n","Epoch 869/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0136 - accuracy: 0.9972 - val_loss: 0.2468 - val_accuracy: 0.9726\n","Epoch 870/1500\n","42/42 [==============================] - 1s 30ms/step - loss: 0.0125 - accuracy: 0.9984 - val_loss: 0.2565 - val_accuracy: 0.9718\n","Epoch 871/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0114 - accuracy: 0.9982 - val_loss: 0.2315 - val_accuracy: 0.9713\n","Epoch 872/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 0.2445 - val_accuracy: 0.9709\n","Epoch 873/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0116 - accuracy: 0.9979 - val_loss: 0.2376 - val_accuracy: 0.9717\n","Epoch 874/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0136 - accuracy: 0.9976 - val_loss: 0.2371 - val_accuracy: 0.9722\n","Epoch 875/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0135 - accuracy: 0.9979 - val_loss: 0.2180 - val_accuracy: 0.9702\n","Epoch 876/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0141 - accuracy: 0.9977 - val_loss: 0.2351 - val_accuracy: 0.9717\n","Epoch 877/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0119 - accuracy: 0.9979 - val_loss: 0.2241 - val_accuracy: 0.9702\n","Epoch 878/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0149 - accuracy: 0.9975 - val_loss: 0.2220 - val_accuracy: 0.9709\n","Epoch 879/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0136 - accuracy: 0.9976 - val_loss: 0.2141 - val_accuracy: 0.9705\n","Epoch 880/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0139 - accuracy: 0.9976 - val_loss: 0.2284 - val_accuracy: 0.9726\n","Epoch 881/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0122 - accuracy: 0.9979 - val_loss: 0.2513 - val_accuracy: 0.9720\n","Epoch 882/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0127 - accuracy: 0.9978 - val_loss: 0.2354 - val_accuracy: 0.9724\n","Epoch 883/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0128 - accuracy: 0.9977 - val_loss: 0.2225 - val_accuracy: 0.9717\n","Epoch 884/1500\n","42/42 [==============================] - 1s 30ms/step - loss: 0.0127 - accuracy: 0.9977 - val_loss: 0.2144 - val_accuracy: 0.9698\n","Epoch 885/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0136 - accuracy: 0.9973 - val_loss: 0.2298 - val_accuracy: 0.9715\n","Epoch 886/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9977 - val_loss: 0.2263 - val_accuracy: 0.9715\n","Epoch 887/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0129 - accuracy: 0.9978 - val_loss: 0.2343 - val_accuracy: 0.9709\n","Epoch 888/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0135 - accuracy: 0.9978 - val_loss: 0.2350 - val_accuracy: 0.9711\n","Epoch 889/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0114 - accuracy: 0.9986 - val_loss: 0.2370 - val_accuracy: 0.9713\n","Epoch 890/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0132 - accuracy: 0.9977 - val_loss: 0.2203 - val_accuracy: 0.9691\n","Epoch 891/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0130 - accuracy: 0.9979 - val_loss: 0.2355 - val_accuracy: 0.9705\n","Epoch 892/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0135 - accuracy: 0.9972 - val_loss: 0.2371 - val_accuracy: 0.9705\n","Epoch 893/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0122 - accuracy: 0.9981 - val_loss: 0.2299 - val_accuracy: 0.9702\n","Epoch 894/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0155 - accuracy: 0.9972 - val_loss: 0.2303 - val_accuracy: 0.9704\n","Epoch 895/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.2271 - val_accuracy: 0.9707\n","Epoch 896/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9979 - val_loss: 0.2516 - val_accuracy: 0.9709\n","Epoch 897/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.2391 - val_accuracy: 0.9709\n","Epoch 898/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0126 - accuracy: 0.9981 - val_loss: 0.2239 - val_accuracy: 0.9696\n","Epoch 899/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0136 - accuracy: 0.9975 - val_loss: 0.2285 - val_accuracy: 0.9707\n","Epoch 900/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9976 - val_loss: 0.2462 - val_accuracy: 0.9717\n","Epoch 901/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9974 - val_loss: 0.2315 - val_accuracy: 0.9709\n","Epoch 902/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.2365 - val_accuracy: 0.9705\n","Epoch 903/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.2239 - val_accuracy: 0.9691\n","Epoch 904/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.2382 - val_accuracy: 0.9717\n","Epoch 905/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0107 - accuracy: 0.9990 - val_loss: 0.2414 - val_accuracy: 0.9718\n","Epoch 906/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0140 - accuracy: 0.9974 - val_loss: 0.2334 - val_accuracy: 0.9713\n","Epoch 907/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9979 - val_loss: 0.2517 - val_accuracy: 0.9711\n","Epoch 908/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0120 - accuracy: 0.9982 - val_loss: 0.2274 - val_accuracy: 0.9707\n","Epoch 909/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0112 - accuracy: 0.9984 - val_loss: 0.2413 - val_accuracy: 0.9711\n","Epoch 910/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.2375 - val_accuracy: 0.9715\n","Epoch 911/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0130 - accuracy: 0.9979 - val_loss: 0.2253 - val_accuracy: 0.9711\n","Epoch 912/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0143 - accuracy: 0.9977 - val_loss: 0.2393 - val_accuracy: 0.9718\n","Epoch 913/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0132 - accuracy: 0.9981 - val_loss: 0.2376 - val_accuracy: 0.9718\n","Epoch 914/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9978 - val_loss: 0.2215 - val_accuracy: 0.9707\n","Epoch 915/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0126 - accuracy: 0.9983 - val_loss: 0.2348 - val_accuracy: 0.9713\n","Epoch 916/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0141 - accuracy: 0.9976 - val_loss: 0.2298 - val_accuracy: 0.9711\n","Epoch 917/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0136 - accuracy: 0.9973 - val_loss: 0.2285 - val_accuracy: 0.9700\n","Epoch 918/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.2449 - val_accuracy: 0.9707\n","Epoch 919/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 0.2337 - val_accuracy: 0.9711\n","Epoch 920/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0135 - accuracy: 0.9979 - val_loss: 0.2208 - val_accuracy: 0.9696\n","Epoch 921/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.2324 - val_accuracy: 0.9709\n","Epoch 922/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.2471 - val_accuracy: 0.9715\n","Epoch 923/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0149 - accuracy: 0.9971 - val_loss: 0.2208 - val_accuracy: 0.9685\n","Epoch 924/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0148 - accuracy: 0.9973 - val_loss: 0.2479 - val_accuracy: 0.9717\n","Epoch 925/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0119 - accuracy: 0.9980 - val_loss: 0.2444 - val_accuracy: 0.9711\n","Epoch 926/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9980 - val_loss: 0.2553 - val_accuracy: 0.9720\n","Epoch 927/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0137 - accuracy: 0.9979 - val_loss: 0.2423 - val_accuracy: 0.9720\n","Epoch 928/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9973 - val_loss: 0.2339 - val_accuracy: 0.9704\n","Epoch 929/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 0.2459 - val_accuracy: 0.9713\n","Epoch 930/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0129 - accuracy: 0.9977 - val_loss: 0.2312 - val_accuracy: 0.9707\n","Epoch 931/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0118 - accuracy: 0.9982 - val_loss: 0.2357 - val_accuracy: 0.9713\n","Epoch 932/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0114 - accuracy: 0.9981 - val_loss: 0.2576 - val_accuracy: 0.9709\n","Epoch 933/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0125 - accuracy: 0.9979 - val_loss: 0.2462 - val_accuracy: 0.9724\n","Epoch 934/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 0.2342 - val_accuracy: 0.9711\n","Epoch 935/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0112 - accuracy: 0.9985 - val_loss: 0.2542 - val_accuracy: 0.9711\n","Epoch 936/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0150 - accuracy: 0.9967 - val_loss: 0.2485 - val_accuracy: 0.9700\n","Epoch 937/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0118 - accuracy: 0.9982 - val_loss: 0.2747 - val_accuracy: 0.9711\n","Epoch 938/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0134 - accuracy: 0.9980 - val_loss: 0.2298 - val_accuracy: 0.9707\n","Epoch 939/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 0.2376 - val_accuracy: 0.9709\n","Epoch 940/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 0.2423 - val_accuracy: 0.9713\n","Epoch 941/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.2407 - val_accuracy: 0.9718\n","Epoch 942/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0121 - accuracy: 0.9979 - val_loss: 0.2432 - val_accuracy: 0.9718\n","Epoch 943/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0121 - accuracy: 0.9981 - val_loss: 0.2414 - val_accuracy: 0.9715\n","Epoch 944/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0154 - accuracy: 0.9970 - val_loss: 0.2402 - val_accuracy: 0.9707\n","Epoch 945/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9974 - val_loss: 0.2427 - val_accuracy: 0.9709\n","Epoch 946/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9981 - val_loss: 0.2343 - val_accuracy: 0.9705\n","Epoch 947/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0149 - accuracy: 0.9966 - val_loss: 0.2789 - val_accuracy: 0.9707\n","Epoch 948/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0135 - accuracy: 0.9972 - val_loss: 0.2362 - val_accuracy: 0.9711\n","Epoch 949/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0116 - accuracy: 0.9986 - val_loss: 0.2464 - val_accuracy: 0.9709\n","Epoch 950/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9977 - val_loss: 0.2511 - val_accuracy: 0.9715\n","Epoch 951/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0117 - accuracy: 0.9982 - val_loss: 0.2575 - val_accuracy: 0.9707\n","Epoch 952/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0111 - accuracy: 0.9981 - val_loss: 0.2424 - val_accuracy: 0.9713\n","Epoch 953/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0125 - accuracy: 0.9978 - val_loss: 0.2397 - val_accuracy: 0.9713\n","Epoch 954/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0121 - accuracy: 0.9984 - val_loss: 0.2234 - val_accuracy: 0.9691\n","Epoch 955/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 0.2576 - val_accuracy: 0.9711\n","Epoch 956/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.2396 - val_accuracy: 0.9713\n","Epoch 957/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 0.2417 - val_accuracy: 0.9722\n","Epoch 958/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0136 - accuracy: 0.9976 - val_loss: 0.2375 - val_accuracy: 0.9709\n","Epoch 959/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.2619 - val_accuracy: 0.9709\n","Epoch 960/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0139 - accuracy: 0.9977 - val_loss: 0.2523 - val_accuracy: 0.9709\n","Epoch 961/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0118 - accuracy: 0.9982 - val_loss: 0.2350 - val_accuracy: 0.9702\n","Epoch 962/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9971 - val_loss: 0.2293 - val_accuracy: 0.9702\n","Epoch 963/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0111 - accuracy: 0.9982 - val_loss: 0.2380 - val_accuracy: 0.9711\n","Epoch 964/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0116 - accuracy: 0.9986 - val_loss: 0.2394 - val_accuracy: 0.9707\n","Epoch 965/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.2318 - val_accuracy: 0.9707\n","Epoch 966/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9975 - val_loss: 0.2318 - val_accuracy: 0.9704\n","Epoch 967/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0114 - accuracy: 0.9986 - val_loss: 0.2311 - val_accuracy: 0.9705\n","Epoch 968/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0128 - accuracy: 0.9974 - val_loss: 0.2590 - val_accuracy: 0.9715\n","Epoch 969/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0136 - accuracy: 0.9979 - val_loss: 0.2374 - val_accuracy: 0.9709\n","Epoch 970/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9981 - val_loss: 0.2279 - val_accuracy: 0.9711\n","Epoch 971/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0120 - accuracy: 0.9982 - val_loss: 0.2479 - val_accuracy: 0.9717\n","Epoch 972/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0135 - accuracy: 0.9979 - val_loss: 0.2312 - val_accuracy: 0.9709\n","Epoch 973/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0117 - accuracy: 0.9986 - val_loss: 0.2373 - val_accuracy: 0.9709\n","Epoch 974/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9978 - val_loss: 0.2467 - val_accuracy: 0.9715\n","Epoch 975/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0124 - accuracy: 0.9981 - val_loss: 0.2510 - val_accuracy: 0.9720\n","Epoch 976/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0128 - accuracy: 0.9980 - val_loss: 0.2440 - val_accuracy: 0.9711\n","Epoch 977/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0132 - accuracy: 0.9978 - val_loss: 0.2274 - val_accuracy: 0.9724\n","Epoch 978/1500\n","42/42 [==============================] - 1s 30ms/step - loss: 0.0113 - accuracy: 0.9981 - val_loss: 0.2469 - val_accuracy: 0.9715\n","Epoch 979/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0147 - accuracy: 0.9970 - val_loss: 0.2310 - val_accuracy: 0.9720\n","Epoch 980/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0135 - accuracy: 0.9971 - val_loss: 0.2471 - val_accuracy: 0.9717\n","Epoch 981/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0128 - accuracy: 0.9982 - val_loss: 0.2475 - val_accuracy: 0.9724\n","Epoch 982/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.2427 - val_accuracy: 0.9726\n","Epoch 983/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0119 - accuracy: 0.9985 - val_loss: 0.2389 - val_accuracy: 0.9724\n","Epoch 984/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0128 - accuracy: 0.9977 - val_loss: 0.2429 - val_accuracy: 0.9720\n","Epoch 985/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9976 - val_loss: 0.2325 - val_accuracy: 0.9722\n","Epoch 986/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9982 - val_loss: 0.2477 - val_accuracy: 0.9718\n","Epoch 987/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.2309 - val_accuracy: 0.9715\n","Epoch 988/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0134 - accuracy: 0.9973 - val_loss: 0.2430 - val_accuracy: 0.9718\n","Epoch 989/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0133 - accuracy: 0.9976 - val_loss: 0.2835 - val_accuracy: 0.9720\n","Epoch 990/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.2316 - val_accuracy: 0.9711\n","Epoch 991/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0105 - accuracy: 0.9988 - val_loss: 0.2220 - val_accuracy: 0.9722\n","Epoch 992/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.2367 - val_accuracy: 0.9713\n","Epoch 993/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0140 - accuracy: 0.9972 - val_loss: 0.2435 - val_accuracy: 0.9726\n","Epoch 994/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.2255 - val_accuracy: 0.9717\n","Epoch 995/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0108 - accuracy: 0.9987 - val_loss: 0.2353 - val_accuracy: 0.9724\n","Epoch 996/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0102 - accuracy: 0.9991 - val_loss: 0.2463 - val_accuracy: 0.9726\n","Epoch 997/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0119 - accuracy: 0.9980 - val_loss: 0.2365 - val_accuracy: 0.9728\n","Epoch 998/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0122 - accuracy: 0.9979 - val_loss: 0.2254 - val_accuracy: 0.9722\n","Epoch 999/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0121 - accuracy: 0.9982 - val_loss: 0.2369 - val_accuracy: 0.9724\n","Epoch 1000/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0120 - accuracy: 0.9983 - val_loss: 0.2375 - val_accuracy: 0.9722\n","Epoch 1001/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0111 - accuracy: 0.9989 - val_loss: 0.2396 - val_accuracy: 0.9720\n","Epoch 1002/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0130 - accuracy: 0.9977 - val_loss: 0.2382 - val_accuracy: 0.9715\n","Epoch 1003/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0125 - accuracy: 0.9973 - val_loss: 0.2535 - val_accuracy: 0.9722\n","Epoch 1004/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0128 - accuracy: 0.9980 - val_loss: 0.2600 - val_accuracy: 0.9724\n","Epoch 1005/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0121 - accuracy: 0.9983 - val_loss: 0.2395 - val_accuracy: 0.9718\n","Epoch 1006/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 0.9987 - val_loss: 0.2547 - val_accuracy: 0.9720\n","Epoch 1007/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.2479 - val_accuracy: 0.9720\n","Epoch 1008/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0119 - accuracy: 0.9979 - val_loss: 0.2319 - val_accuracy: 0.9713\n","Epoch 1009/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.2249 - val_accuracy: 0.9707\n","Epoch 1010/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0115 - accuracy: 0.9980 - val_loss: 0.2458 - val_accuracy: 0.9713\n","Epoch 1011/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0123 - accuracy: 0.9979 - val_loss: 0.2589 - val_accuracy: 0.9707\n","Epoch 1012/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0117 - accuracy: 0.9978 - val_loss: 0.2464 - val_accuracy: 0.9715\n","Epoch 1013/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0118 - accuracy: 0.9981 - val_loss: 0.2530 - val_accuracy: 0.9709\n","Epoch 1014/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 0.2336 - val_accuracy: 0.9698\n","Epoch 1015/1500\n","42/42 [==============================] - 1s 34ms/step - loss: 0.0129 - accuracy: 0.9976 - val_loss: 0.2424 - val_accuracy: 0.9711\n","Epoch 1016/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0132 - accuracy: 0.9978 - val_loss: 0.2538 - val_accuracy: 0.9711\n","Epoch 1017/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0131 - accuracy: 0.9978 - val_loss: 0.2536 - val_accuracy: 0.9711\n","Epoch 1018/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0134 - accuracy: 0.9980 - val_loss: 0.2278 - val_accuracy: 0.9691\n","Epoch 1019/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0112 - accuracy: 0.9981 - val_loss: 0.2444 - val_accuracy: 0.9700\n","Epoch 1020/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0114 - accuracy: 0.9980 - val_loss: 0.2659 - val_accuracy: 0.9718\n","Epoch 1021/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.2457 - val_accuracy: 0.9707\n","Epoch 1022/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9974 - val_loss: 0.2378 - val_accuracy: 0.9705\n","Epoch 1023/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0116 - accuracy: 0.9983 - val_loss: 0.2484 - val_accuracy: 0.9704\n","Epoch 1024/1500\n","42/42 [==============================] - 1s 34ms/step - loss: 0.0122 - accuracy: 0.9977 - val_loss: 0.2593 - val_accuracy: 0.9713\n","Epoch 1025/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0121 - accuracy: 0.9979 - val_loss: 0.2473 - val_accuracy: 0.9707\n","Epoch 1026/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0128 - accuracy: 0.9982 - val_loss: 0.2439 - val_accuracy: 0.9711\n","Epoch 1027/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 0.9981 - val_loss: 0.2326 - val_accuracy: 0.9694\n","Epoch 1028/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9978 - val_loss: 0.2392 - val_accuracy: 0.9718\n","Epoch 1029/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0113 - accuracy: 0.9987 - val_loss: 0.2530 - val_accuracy: 0.9718\n","Epoch 1030/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.2396 - val_accuracy: 0.9709\n","Epoch 1031/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0132 - accuracy: 0.9973 - val_loss: 0.2286 - val_accuracy: 0.9704\n","Epoch 1032/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.2702 - val_accuracy: 0.9709\n","Epoch 1033/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0140 - accuracy: 0.9981 - val_loss: 0.2607 - val_accuracy: 0.9715\n","Epoch 1034/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0125 - accuracy: 0.9979 - val_loss: 0.2382 - val_accuracy: 0.9705\n","Epoch 1035/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0135 - accuracy: 0.9971 - val_loss: 0.2484 - val_accuracy: 0.9709\n","Epoch 1036/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 0.2412 - val_accuracy: 0.9696\n","Epoch 1037/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0116 - accuracy: 0.9981 - val_loss: 0.2481 - val_accuracy: 0.9704\n","Epoch 1038/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0131 - accuracy: 0.9978 - val_loss: 0.2548 - val_accuracy: 0.9709\n","Epoch 1039/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9978 - val_loss: 0.2553 - val_accuracy: 0.9717\n","Epoch 1040/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0137 - accuracy: 0.9971 - val_loss: 0.2513 - val_accuracy: 0.9711\n","Epoch 1041/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0118 - accuracy: 0.9984 - val_loss: 0.2454 - val_accuracy: 0.9702\n","Epoch 1042/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0147 - accuracy: 0.9966 - val_loss: 0.2566 - val_accuracy: 0.9726\n","Epoch 1043/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0120 - accuracy: 0.9980 - val_loss: 0.2437 - val_accuracy: 0.9713\n","Epoch 1044/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0129 - accuracy: 0.9977 - val_loss: 0.2291 - val_accuracy: 0.9704\n","Epoch 1045/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0142 - accuracy: 0.9979 - val_loss: 0.2589 - val_accuracy: 0.9724\n","Epoch 1046/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0127 - accuracy: 0.9975 - val_loss: 0.2300 - val_accuracy: 0.9704\n","Epoch 1047/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0145 - accuracy: 0.9977 - val_loss: 0.2358 - val_accuracy: 0.9707\n","Epoch 1048/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0118 - accuracy: 0.9981 - val_loss: 0.2311 - val_accuracy: 0.9711\n","Epoch 1049/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0143 - accuracy: 0.9976 - val_loss: 0.2382 - val_accuracy: 0.9709\n","Epoch 1050/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9976 - val_loss: 0.2433 - val_accuracy: 0.9715\n","Epoch 1051/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0114 - accuracy: 0.9989 - val_loss: 0.2300 - val_accuracy: 0.9711\n","Epoch 1052/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0115 - accuracy: 0.9982 - val_loss: 0.2537 - val_accuracy: 0.9717\n","Epoch 1053/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.2482 - val_accuracy: 0.9724\n","Epoch 1054/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0122 - accuracy: 0.9979 - val_loss: 0.2386 - val_accuracy: 0.9718\n","Epoch 1055/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0118 - accuracy: 0.9979 - val_loss: 0.2381 - val_accuracy: 0.9720\n","Epoch 1056/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0110 - accuracy: 0.9983 - val_loss: 0.2483 - val_accuracy: 0.9724\n","Epoch 1057/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.2327 - val_accuracy: 0.9711\n","Epoch 1058/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.2272 - val_accuracy: 0.9704\n","Epoch 1059/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0140 - accuracy: 0.9973 - val_loss: 0.2325 - val_accuracy: 0.9713\n","Epoch 1060/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0111 - accuracy: 0.9987 - val_loss: 0.2411 - val_accuracy: 0.9711\n","Epoch 1061/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0123 - accuracy: 0.9978 - val_loss: 0.2363 - val_accuracy: 0.9711\n","Epoch 1062/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 0.2498 - val_accuracy: 0.9717\n","Epoch 1063/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0147 - accuracy: 0.9970 - val_loss: 0.2600 - val_accuracy: 0.9715\n","Epoch 1064/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.2433 - val_accuracy: 0.9711\n","Epoch 1065/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0139 - accuracy: 0.9971 - val_loss: 0.2493 - val_accuracy: 0.9713\n","Epoch 1066/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9978 - val_loss: 0.2413 - val_accuracy: 0.9711\n","Epoch 1067/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0117 - accuracy: 0.9980 - val_loss: 0.2445 - val_accuracy: 0.9711\n","Epoch 1068/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0122 - accuracy: 0.9980 - val_loss: 0.2584 - val_accuracy: 0.9715\n","Epoch 1069/1500\n","42/42 [==============================] - 1s 34ms/step - loss: 0.0121 - accuracy: 0.9978 - val_loss: 0.2412 - val_accuracy: 0.9707\n","Epoch 1070/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9984 - val_loss: 0.2353 - val_accuracy: 0.9709\n","Epoch 1071/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0144 - accuracy: 0.9970 - val_loss: 0.2498 - val_accuracy: 0.9711\n","Epoch 1072/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0143 - accuracy: 0.9978 - val_loss: 0.2517 - val_accuracy: 0.9707\n","Epoch 1073/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.2531 - val_accuracy: 0.9711\n","Epoch 1074/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0134 - accuracy: 0.9980 - val_loss: 0.2555 - val_accuracy: 0.9713\n","Epoch 1075/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0120 - accuracy: 0.9983 - val_loss: 0.2389 - val_accuracy: 0.9696\n","Epoch 1076/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0120 - accuracy: 0.9983 - val_loss: 0.2347 - val_accuracy: 0.9696\n","Epoch 1077/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0114 - accuracy: 0.9984 - val_loss: 0.2541 - val_accuracy: 0.9711\n","Epoch 1078/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9981 - val_loss: 0.2368 - val_accuracy: 0.9698\n","Epoch 1079/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0120 - accuracy: 0.9981 - val_loss: 0.2400 - val_accuracy: 0.9698\n","Epoch 1080/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9979 - val_loss: 0.2651 - val_accuracy: 0.9715\n","Epoch 1081/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0154 - accuracy: 0.9971 - val_loss: 0.2736 - val_accuracy: 0.9709\n","Epoch 1082/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.2568 - val_accuracy: 0.9709\n","Epoch 1083/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0125 - accuracy: 0.9981 - val_loss: 0.2310 - val_accuracy: 0.9704\n","Epoch 1084/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.2391 - val_accuracy: 0.9711\n","Epoch 1085/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0123 - accuracy: 0.9980 - val_loss: 0.2448 - val_accuracy: 0.9711\n","Epoch 1086/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0144 - accuracy: 0.9971 - val_loss: 0.2547 - val_accuracy: 0.9715\n","Epoch 1087/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0142 - accuracy: 0.9966 - val_loss: 0.2483 - val_accuracy: 0.9715\n","Epoch 1088/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.2471 - val_accuracy: 0.9713\n","Epoch 1089/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 0.9988 - val_loss: 0.2448 - val_accuracy: 0.9711\n","Epoch 1090/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0134 - accuracy: 0.9978 - val_loss: 0.2414 - val_accuracy: 0.9709\n","Epoch 1091/1500\n","42/42 [==============================] - 1s 30ms/step - loss: 0.0122 - accuracy: 0.9981 - val_loss: 0.2615 - val_accuracy: 0.9718\n","Epoch 1092/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0122 - accuracy: 0.9983 - val_loss: 0.2426 - val_accuracy: 0.9709\n","Epoch 1093/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 0.2637 - val_accuracy: 0.9713\n","Epoch 1094/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0112 - accuracy: 0.9985 - val_loss: 0.2619 - val_accuracy: 0.9715\n","Epoch 1095/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0128 - accuracy: 0.9972 - val_loss: 0.2331 - val_accuracy: 0.9704\n","Epoch 1096/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0136 - accuracy: 0.9973 - val_loss: 0.2493 - val_accuracy: 0.9715\n","Epoch 1097/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0113 - accuracy: 0.9981 - val_loss: 0.2470 - val_accuracy: 0.9713\n","Epoch 1098/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.2567 - val_accuracy: 0.9720\n","Epoch 1099/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.2325 - val_accuracy: 0.9711\n","Epoch 1100/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0140 - accuracy: 0.9979 - val_loss: 0.2416 - val_accuracy: 0.9720\n","Epoch 1101/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9978 - val_loss: 0.2394 - val_accuracy: 0.9717\n","Epoch 1102/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0128 - accuracy: 0.9982 - val_loss: 0.2368 - val_accuracy: 0.9713\n","Epoch 1103/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0122 - accuracy: 0.9979 - val_loss: 0.2310 - val_accuracy: 0.9713\n","Epoch 1104/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0138 - accuracy: 0.9978 - val_loss: 0.2414 - val_accuracy: 0.9720\n","Epoch 1105/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0131 - accuracy: 0.9978 - val_loss: 0.2271 - val_accuracy: 0.9704\n","Epoch 1106/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9981 - val_loss: 0.2376 - val_accuracy: 0.9711\n","Epoch 1107/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0122 - accuracy: 0.9977 - val_loss: 0.2366 - val_accuracy: 0.9705\n","Epoch 1108/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.2484 - val_accuracy: 0.9709\n","Epoch 1109/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0163 - accuracy: 0.9966 - val_loss: 0.2624 - val_accuracy: 0.9722\n","Epoch 1110/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0125 - accuracy: 0.9984 - val_loss: 0.2395 - val_accuracy: 0.9702\n","Epoch 1111/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0114 - accuracy: 0.9985 - val_loss: 0.2605 - val_accuracy: 0.9709\n","Epoch 1112/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0113 - accuracy: 0.9980 - val_loss: 0.2548 - val_accuracy: 0.9705\n","Epoch 1113/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9980 - val_loss: 0.2442 - val_accuracy: 0.9705\n","Epoch 1114/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0130 - accuracy: 0.9981 - val_loss: 0.2353 - val_accuracy: 0.9707\n","Epoch 1115/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0115 - accuracy: 0.9979 - val_loss: 0.2447 - val_accuracy: 0.9715\n","Epoch 1116/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 0.9991 - val_loss: 0.2580 - val_accuracy: 0.9717\n","Epoch 1117/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0122 - accuracy: 0.9982 - val_loss: 0.2495 - val_accuracy: 0.9724\n","Epoch 1118/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9977 - val_loss: 0.2423 - val_accuracy: 0.9715\n","Epoch 1119/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0120 - accuracy: 0.9982 - val_loss: 0.2342 - val_accuracy: 0.9713\n","Epoch 1120/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0107 - accuracy: 0.9984 - val_loss: 0.2347 - val_accuracy: 0.9715\n","Epoch 1121/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0117 - accuracy: 0.9985 - val_loss: 0.2277 - val_accuracy: 0.9704\n","Epoch 1122/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0126 - accuracy: 0.9976 - val_loss: 0.2403 - val_accuracy: 0.9720\n","Epoch 1123/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.2490 - val_accuracy: 0.9724\n","Epoch 1124/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.2174 - val_accuracy: 0.9685\n","Epoch 1125/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0122 - accuracy: 0.9982 - val_loss: 0.2454 - val_accuracy: 0.9724\n","Epoch 1126/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0137 - accuracy: 0.9976 - val_loss: 0.2429 - val_accuracy: 0.9724\n","Epoch 1127/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0125 - accuracy: 0.9982 - val_loss: 0.2303 - val_accuracy: 0.9724\n","Epoch 1128/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0151 - accuracy: 0.9974 - val_loss: 0.2198 - val_accuracy: 0.9700\n","Epoch 1129/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0116 - accuracy: 0.9981 - val_loss: 0.2374 - val_accuracy: 0.9728\n","Epoch 1130/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9977 - val_loss: 0.2583 - val_accuracy: 0.9722\n","Epoch 1131/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9977 - val_loss: 0.2665 - val_accuracy: 0.9720\n","Epoch 1132/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0163 - accuracy: 0.9973 - val_loss: 0.2353 - val_accuracy: 0.9709\n","Epoch 1133/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 0.9983 - val_loss: 0.2498 - val_accuracy: 0.9715\n","Epoch 1134/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0112 - accuracy: 0.9983 - val_loss: 0.2405 - val_accuracy: 0.9704\n","Epoch 1135/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0126 - accuracy: 0.9978 - val_loss: 0.2390 - val_accuracy: 0.9700\n","Epoch 1136/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9974 - val_loss: 0.2438 - val_accuracy: 0.9718\n","Epoch 1137/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9977 - val_loss: 0.2432 - val_accuracy: 0.9713\n","Epoch 1138/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9981 - val_loss: 0.2897 - val_accuracy: 0.9715\n","Epoch 1139/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.2333 - val_accuracy: 0.9709\n","Epoch 1140/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9977 - val_loss: 0.2307 - val_accuracy: 0.9707\n","Epoch 1141/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 0.2363 - val_accuracy: 0.9715\n","Epoch 1142/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0111 - accuracy: 0.9981 - val_loss: 0.2610 - val_accuracy: 0.9717\n","Epoch 1143/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0104 - accuracy: 0.9988 - val_loss: 0.2514 - val_accuracy: 0.9718\n","Epoch 1144/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.2516 - val_accuracy: 0.9720\n","Epoch 1145/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0128 - accuracy: 0.9980 - val_loss: 0.2485 - val_accuracy: 0.9711\n","Epoch 1146/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0122 - accuracy: 0.9977 - val_loss: 0.2498 - val_accuracy: 0.9717\n","Epoch 1147/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 0.9981 - val_loss: 0.2403 - val_accuracy: 0.9705\n","Epoch 1148/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0112 - accuracy: 0.9983 - val_loss: 0.2462 - val_accuracy: 0.9702\n","Epoch 1149/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0123 - accuracy: 0.9986 - val_loss: 0.2551 - val_accuracy: 0.9713\n","Epoch 1150/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0107 - accuracy: 0.9986 - val_loss: 0.2418 - val_accuracy: 0.9702\n","Epoch 1151/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0115 - accuracy: 0.9980 - val_loss: 0.2567 - val_accuracy: 0.9713\n","Epoch 1152/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: 0.2335 - val_accuracy: 0.9698\n","Epoch 1153/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.2589 - val_accuracy: 0.9707\n","Epoch 1154/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.2410 - val_accuracy: 0.9702\n","Epoch 1155/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0121 - accuracy: 0.9980 - val_loss: 0.2463 - val_accuracy: 0.9705\n","Epoch 1156/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0117 - accuracy: 0.9979 - val_loss: 0.2473 - val_accuracy: 0.9702\n","Epoch 1157/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0118 - accuracy: 0.9982 - val_loss: 0.2483 - val_accuracy: 0.9707\n","Epoch 1158/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9975 - val_loss: 0.2501 - val_accuracy: 0.9696\n","Epoch 1159/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9978 - val_loss: 0.2406 - val_accuracy: 0.9700\n","Epoch 1160/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0125 - accuracy: 0.9981 - val_loss: 0.2483 - val_accuracy: 0.9707\n","Epoch 1161/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0131 - accuracy: 0.9982 - val_loss: 0.2677 - val_accuracy: 0.9717\n","Epoch 1162/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0118 - accuracy: 0.9979 - val_loss: 0.2426 - val_accuracy: 0.9711\n","Epoch 1163/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0139 - accuracy: 0.9971 - val_loss: 0.2477 - val_accuracy: 0.9711\n","Epoch 1164/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9977 - val_loss: 0.2529 - val_accuracy: 0.9713\n","Epoch 1165/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 0.2521 - val_accuracy: 0.9715\n","Epoch 1166/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0111 - accuracy: 0.9987 - val_loss: 0.2369 - val_accuracy: 0.9707\n","Epoch 1167/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0134 - accuracy: 0.9975 - val_loss: 0.2449 - val_accuracy: 0.9718\n","Epoch 1168/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.2464 - val_accuracy: 0.9718\n","Epoch 1169/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0117 - accuracy: 0.9979 - val_loss: 0.2434 - val_accuracy: 0.9715\n","Epoch 1170/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0113 - accuracy: 0.9982 - val_loss: 0.2503 - val_accuracy: 0.9722\n","Epoch 1171/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0120 - accuracy: 0.9980 - val_loss: 0.2523 - val_accuracy: 0.9718\n","Epoch 1172/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0124 - accuracy: 0.9982 - val_loss: 0.2519 - val_accuracy: 0.9715\n","Epoch 1173/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0137 - accuracy: 0.9977 - val_loss: 0.2384 - val_accuracy: 0.9700\n","Epoch 1174/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.2587 - val_accuracy: 0.9724\n","Epoch 1175/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0098 - accuracy: 0.9992 - val_loss: 0.2534 - val_accuracy: 0.9718\n","Epoch 1176/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.2570 - val_accuracy: 0.9718\n","Epoch 1177/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0117 - accuracy: 0.9983 - val_loss: 0.2422 - val_accuracy: 0.9713\n","Epoch 1178/1500\n","42/42 [==============================] - 1s 34ms/step - loss: 0.0125 - accuracy: 0.9975 - val_loss: 0.2500 - val_accuracy: 0.9722\n","Epoch 1179/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.2469 - val_accuracy: 0.9724\n","Epoch 1180/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0120 - accuracy: 0.9980 - val_loss: 0.2310 - val_accuracy: 0.9702\n","Epoch 1181/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0134 - accuracy: 0.9974 - val_loss: 0.2497 - val_accuracy: 0.9717\n","Epoch 1182/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 0.2491 - val_accuracy: 0.9715\n","Epoch 1183/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0122 - accuracy: 0.9978 - val_loss: 0.2417 - val_accuracy: 0.9711\n","Epoch 1184/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.2447 - val_accuracy: 0.9718\n","Epoch 1185/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9976 - val_loss: 0.2412 - val_accuracy: 0.9715\n","Epoch 1186/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0121 - accuracy: 0.9979 - val_loss: 0.2551 - val_accuracy: 0.9717\n","Epoch 1187/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0104 - accuracy: 0.9986 - val_loss: 0.2473 - val_accuracy: 0.9709\n","Epoch 1188/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9977 - val_loss: 0.2432 - val_accuracy: 0.9711\n","Epoch 1189/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0154 - accuracy: 0.9975 - val_loss: 0.2562 - val_accuracy: 0.9713\n","Epoch 1190/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 0.9974 - val_loss: 0.2408 - val_accuracy: 0.9717\n","Epoch 1191/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0137 - accuracy: 0.9976 - val_loss: 0.2414 - val_accuracy: 0.9713\n","Epoch 1192/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0134 - accuracy: 0.9978 - val_loss: 0.2549 - val_accuracy: 0.9717\n","Epoch 1193/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.2379 - val_accuracy: 0.9715\n","Epoch 1194/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 0.2512 - val_accuracy: 0.9718\n","Epoch 1195/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0134 - accuracy: 0.9978 - val_loss: 0.2157 - val_accuracy: 0.9696\n","Epoch 1196/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0147 - accuracy: 0.9978 - val_loss: 0.2445 - val_accuracy: 0.9717\n","Epoch 1197/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0137 - accuracy: 0.9975 - val_loss: 0.2470 - val_accuracy: 0.9709\n","Epoch 1198/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0145 - accuracy: 0.9972 - val_loss: 0.2245 - val_accuracy: 0.9709\n","Epoch 1199/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9978 - val_loss: 0.2340 - val_accuracy: 0.9724\n","Epoch 1200/1500\n","42/42 [==============================] - 1s 34ms/step - loss: 0.0145 - accuracy: 0.9971 - val_loss: 0.2235 - val_accuracy: 0.9698\n","Epoch 1201/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0143 - accuracy: 0.9974 - val_loss: 0.2524 - val_accuracy: 0.9718\n","Epoch 1202/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.2244 - val_accuracy: 0.9705\n","Epoch 1203/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.2626 - val_accuracy: 0.9722\n","Epoch 1204/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0164 - accuracy: 0.9968 - val_loss: 0.2170 - val_accuracy: 0.9689\n","Epoch 1205/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.2341 - val_accuracy: 0.9709\n","Epoch 1206/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0103 - accuracy: 0.9987 - val_loss: 0.2374 - val_accuracy: 0.9715\n","Epoch 1207/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9978 - val_loss: 0.2297 - val_accuracy: 0.9700\n","Epoch 1208/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0110 - accuracy: 0.9984 - val_loss: 0.2449 - val_accuracy: 0.9715\n","Epoch 1209/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0126 - accuracy: 0.9975 - val_loss: 0.2595 - val_accuracy: 0.9722\n","Epoch 1210/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0136 - accuracy: 0.9968 - val_loss: 0.2394 - val_accuracy: 0.9709\n","Epoch 1211/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0117 - accuracy: 0.9979 - val_loss: 0.2583 - val_accuracy: 0.9726\n","Epoch 1212/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0120 - accuracy: 0.9981 - val_loss: 0.2537 - val_accuracy: 0.9713\n","Epoch 1213/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0107 - accuracy: 0.9984 - val_loss: 0.2683 - val_accuracy: 0.9726\n","Epoch 1214/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0114 - accuracy: 0.9984 - val_loss: 0.2479 - val_accuracy: 0.9713\n","Epoch 1215/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 0.2408 - val_accuracy: 0.9702\n","Epoch 1216/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0132 - accuracy: 0.9978 - val_loss: 0.2496 - val_accuracy: 0.9717\n","Epoch 1217/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: 0.2499 - val_accuracy: 0.9709\n","Epoch 1218/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.2576 - val_accuracy: 0.9724\n","Epoch 1219/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0130 - accuracy: 0.9979 - val_loss: 0.2576 - val_accuracy: 0.9724\n","Epoch 1220/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0115 - accuracy: 0.9980 - val_loss: 0.2548 - val_accuracy: 0.9722\n","Epoch 1221/1500\n","42/42 [==============================] - 1s 34ms/step - loss: 0.0130 - accuracy: 0.9973 - val_loss: 0.2551 - val_accuracy: 0.9715\n","Epoch 1222/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 0.2486 - val_accuracy: 0.9718\n","Epoch 1223/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0148 - accuracy: 0.9974 - val_loss: 0.2495 - val_accuracy: 0.9726\n","Epoch 1224/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0114 - accuracy: 0.9980 - val_loss: 0.2495 - val_accuracy: 0.9728\n","Epoch 1225/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0109 - accuracy: 0.9989 - val_loss: 0.2308 - val_accuracy: 0.9715\n","Epoch 1226/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 0.2431 - val_accuracy: 0.9724\n","Epoch 1227/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0118 - accuracy: 0.9982 - val_loss: 0.2275 - val_accuracy: 0.9709\n","Epoch 1228/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: 0.2269 - val_accuracy: 0.9722\n","Epoch 1229/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0109 - accuracy: 0.9986 - val_loss: 0.2389 - val_accuracy: 0.9728\n","Epoch 1230/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.2233 - val_accuracy: 0.9709\n","Epoch 1231/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0120 - accuracy: 0.9978 - val_loss: 0.2311 - val_accuracy: 0.9715\n","Epoch 1232/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.2299 - val_accuracy: 0.9718\n","Epoch 1233/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0130 - accuracy: 0.9977 - val_loss: 0.2245 - val_accuracy: 0.9709\n","Epoch 1234/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.2360 - val_accuracy: 0.9718\n","Epoch 1235/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 0.2462 - val_accuracy: 0.9724\n","Epoch 1236/1500\n","42/42 [==============================] - 1s 30ms/step - loss: 0.0119 - accuracy: 0.9980 - val_loss: 0.2548 - val_accuracy: 0.9718\n","Epoch 1237/1500\n","42/42 [==============================] - 1s 34ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.2425 - val_accuracy: 0.9718\n","Epoch 1238/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 0.9981 - val_loss: 0.2289 - val_accuracy: 0.9715\n","Epoch 1239/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0118 - accuracy: 0.9982 - val_loss: 0.2432 - val_accuracy: 0.9713\n","Epoch 1240/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.2338 - val_accuracy: 0.9722\n","Epoch 1241/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.2458 - val_accuracy: 0.9717\n","Epoch 1242/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0117 - accuracy: 0.9981 - val_loss: 0.2425 - val_accuracy: 0.9718\n","Epoch 1243/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0127 - accuracy: 0.9977 - val_loss: 0.2646 - val_accuracy: 0.9722\n","Epoch 1244/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 0.2345 - val_accuracy: 0.9709\n","Epoch 1245/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0152 - accuracy: 0.9972 - val_loss: 0.2453 - val_accuracy: 0.9715\n","Epoch 1246/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0122 - accuracy: 0.9978 - val_loss: 0.2307 - val_accuracy: 0.9709\n","Epoch 1247/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0122 - accuracy: 0.9979 - val_loss: 0.2532 - val_accuracy: 0.9717\n","Epoch 1248/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.2434 - val_accuracy: 0.9711\n","Epoch 1249/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0110 - accuracy: 0.9981 - val_loss: 0.2456 - val_accuracy: 0.9715\n","Epoch 1250/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0119 - accuracy: 0.9984 - val_loss: 0.2455 - val_accuracy: 0.9718\n","Epoch 1251/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0120 - accuracy: 0.9980 - val_loss: 0.2348 - val_accuracy: 0.9709\n","Epoch 1252/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0125 - accuracy: 0.9981 - val_loss: 0.2479 - val_accuracy: 0.9713\n","Epoch 1253/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0126 - accuracy: 0.9976 - val_loss: 0.2532 - val_accuracy: 0.9715\n","Epoch 1254/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0119 - accuracy: 0.9975 - val_loss: 0.2414 - val_accuracy: 0.9709\n","Epoch 1255/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0130 - accuracy: 0.9977 - val_loss: 0.2352 - val_accuracy: 0.9704\n","Epoch 1256/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0125 - accuracy: 0.9979 - val_loss: 0.2369 - val_accuracy: 0.9713\n","Epoch 1257/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 0.2467 - val_accuracy: 0.9722\n","Epoch 1258/1500\n","42/42 [==============================] - 1s 34ms/step - loss: 0.0148 - accuracy: 0.9976 - val_loss: 0.2215 - val_accuracy: 0.9707\n","Epoch 1259/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.2296 - val_accuracy: 0.9711\n","Epoch 1260/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.2322 - val_accuracy: 0.9709\n","Epoch 1261/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0128 - accuracy: 0.9977 - val_loss: 0.2471 - val_accuracy: 0.9720\n","Epoch 1262/1500\n","42/42 [==============================] - 1s 34ms/step - loss: 0.0118 - accuracy: 0.9982 - val_loss: 0.2294 - val_accuracy: 0.9713\n","Epoch 1263/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.2289 - val_accuracy: 0.9717\n","Epoch 1264/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: 0.2407 - val_accuracy: 0.9713\n","Epoch 1265/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 0.9986 - val_loss: 0.2533 - val_accuracy: 0.9718\n","Epoch 1266/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0130 - accuracy: 0.9981 - val_loss: 0.2363 - val_accuracy: 0.9715\n","Epoch 1267/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0128 - accuracy: 0.9978 - val_loss: 0.2529 - val_accuracy: 0.9720\n","Epoch 1268/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0120 - accuracy: 0.9983 - val_loss: 0.2380 - val_accuracy: 0.9715\n","Epoch 1269/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.2412 - val_accuracy: 0.9720\n","Epoch 1270/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0106 - accuracy: 0.9986 - val_loss: 0.2675 - val_accuracy: 0.9728\n","Epoch 1271/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9978 - val_loss: 0.2349 - val_accuracy: 0.9713\n","Epoch 1272/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0114 - accuracy: 0.9989 - val_loss: 0.2508 - val_accuracy: 0.9715\n","Epoch 1273/1500\n","42/42 [==============================] - 1s 34ms/step - loss: 0.0116 - accuracy: 0.9986 - val_loss: 0.2495 - val_accuracy: 0.9718\n","Epoch 1274/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.2469 - val_accuracy: 0.9715\n","Epoch 1275/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0114 - accuracy: 0.9981 - val_loss: 0.2459 - val_accuracy: 0.9717\n","Epoch 1276/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0115 - accuracy: 0.9984 - val_loss: 0.2564 - val_accuracy: 0.9713\n","Epoch 1277/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0115 - accuracy: 0.9984 - val_loss: 0.2681 - val_accuracy: 0.9715\n","Epoch 1278/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9978 - val_loss: 0.2562 - val_accuracy: 0.9718\n","Epoch 1279/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0115 - accuracy: 0.9981 - val_loss: 0.2272 - val_accuracy: 0.9702\n","Epoch 1280/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 0.9976 - val_loss: 0.2473 - val_accuracy: 0.9711\n","Epoch 1281/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.2316 - val_accuracy: 0.9702\n","Epoch 1282/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0128 - accuracy: 0.9977 - val_loss: 0.2464 - val_accuracy: 0.9720\n","Epoch 1283/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 0.2340 - val_accuracy: 0.9709\n","Epoch 1284/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0125 - accuracy: 0.9981 - val_loss: 0.2394 - val_accuracy: 0.9713\n","Epoch 1285/1500\n","42/42 [==============================] - 1s 31ms/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.2444 - val_accuracy: 0.9718\n","Epoch 1286/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0121 - accuracy: 0.9981 - val_loss: 0.2472 - val_accuracy: 0.9713\n","Epoch 1287/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 0.2632 - val_accuracy: 0.9726\n","Epoch 1288/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 0.2481 - val_accuracy: 0.9720\n","Epoch 1289/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0108 - accuracy: 0.9982 - val_loss: 0.2323 - val_accuracy: 0.9713\n","Epoch 1290/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.2446 - val_accuracy: 0.9726\n","Epoch 1291/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0113 - accuracy: 0.9984 - val_loss: 0.2577 - val_accuracy: 0.9730\n","Epoch 1292/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0110 - accuracy: 0.9988 - val_loss: 0.2601 - val_accuracy: 0.9726\n","Epoch 1293/1500\n","42/42 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9977 - val_loss: 0.2324 - val_accuracy: 0.9724\n","Epoch 1294/1500\n","42/42 [==============================] - 1s 33ms/step - loss: 0.0135 - accuracy: 0.9977 - val_loss: 0.2413 - val_accuracy: 0.9726\n","Epoch 1295/1500\n","41/42 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9985"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_szqJ6rMjWC2","colab_type":"text"},"source":[""]}]}